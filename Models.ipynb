{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T15:24:53.218903418Z",
     "start_time": "2024-04-21T15:24:52.674762814Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d04b62db515eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T15:25:05.499636962Z",
     "start_time": "2024-04-21T15:24:53.263780240Z"
    },
    "collapsed": false,
    "jupyter": {>
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/tweets_features.csv\", encoding='latin')\n",
    "df.drop(['is_after_certain_day', 'Date', 'User', 'Text', 'Time', 'Full_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ed935cc58ad477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T15:25:05.521187027Z",
     "start_time": "2024-04-21T15:25:05.503744505Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Length</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>HasHashtags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>HasMentions</th>\n",
       "      <th>ExclamationMarks</th>\n",
       "      <th>HasExclamationMarks</th>\n",
       "      <th>Emoticons</th>\n",
       "      <th>...</th>\n",
       "      <th>w2v_90</th>\n",
       "      <th>w2v_91</th>\n",
       "      <th>w2v_92</th>\n",
       "      <th>w2v_93</th>\n",
       "      <th>w2v_94</th>\n",
       "      <th>w2v_95</th>\n",
       "      <th>w2v_96</th>\n",
       "      <th>w2v_97</th>\n",
       "      <th>w2v_98</th>\n",
       "      <th>w2v_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576463</td>\n",
       "      <td>0.272287</td>\n",
       "      <td>-0.270659</td>\n",
       "      <td>0.398829</td>\n",
       "      <td>0.806970</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.261823</td>\n",
       "      <td>-0.655965</td>\n",
       "      <td>0.179224</td>\n",
       "      <td>-0.132590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400095</td>\n",
       "      <td>0.262307</td>\n",
       "      <td>0.052329</td>\n",
       "      <td>0.443299</td>\n",
       "      <td>0.895985</td>\n",
       "      <td>0.565586</td>\n",
       "      <td>0.221301</td>\n",
       "      <td>-0.797784</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>0.002357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460558</td>\n",
       "      <td>0.378846</td>\n",
       "      <td>-0.171764</td>\n",
       "      <td>0.227248</td>\n",
       "      <td>0.303033</td>\n",
       "      <td>0.620672</td>\n",
       "      <td>0.146584</td>\n",
       "      <td>-0.615910</td>\n",
       "      <td>0.112132</td>\n",
       "      <td>-0.088989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535103</td>\n",
       "      <td>0.073591</td>\n",
       "      <td>-0.307203</td>\n",
       "      <td>0.651506</td>\n",
       "      <td>0.309582</td>\n",
       "      <td>0.018715</td>\n",
       "      <td>-0.205674</td>\n",
       "      <td>-0.595330</td>\n",
       "      <td>0.333111</td>\n",
       "      <td>0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484578</td>\n",
       "      <td>0.324513</td>\n",
       "      <td>-0.259205</td>\n",
       "      <td>0.183831</td>\n",
       "      <td>0.745856</td>\n",
       "      <td>0.448028</td>\n",
       "      <td>0.359533</td>\n",
       "      <td>-0.555516</td>\n",
       "      <td>-0.176974</td>\n",
       "      <td>-0.091381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target  Weekday  Length  Hashtags  HasHashtags  Mentions  HasMentions  \\\n",
       "0       0        4     111         0        False         0        False   \n",
       "1       0        2     131         0        False         0        False   \n",
       "2       0        1      41         0        False         1         True   \n",
       "3       0        6      72         0        False         0        False   \n",
       "4       1        0      57         0        False         1         True   \n",
       "\n",
       "   ExclamationMarks  HasExclamationMarks Emoticons  ...    w2v_90    w2v_91  \\\n",
       "0                 0                False        []  ...  0.576463  0.272287   \n",
       "1                 0                False        []  ...  0.400095  0.262307   \n",
       "2                 2                 True        []  ...  0.460558  0.378846   \n",
       "3                 0                False        []  ...  0.535103  0.073591   \n",
       "4                 0                False        []  ...  0.484578  0.324513   \n",
       "\n",
       "     w2v_92    w2v_93    w2v_94    w2v_95    w2v_96    w2v_97    w2v_98  \\\n",
       "0 -0.270659  0.398829  0.806970  0.539171  0.261823 -0.655965  0.179224   \n",
       "1  0.052329  0.443299  0.895985  0.565586  0.221301 -0.797784  0.020691   \n",
       "2 -0.171764  0.227248  0.303033  0.620672  0.146584 -0.615910  0.112132   \n",
       "3 -0.307203  0.651506  0.309582  0.018715 -0.205674 -0.595330  0.333111   \n",
       "4 -0.259205  0.183831  0.745856  0.448028  0.359533 -0.555516 -0.176974   \n",
       "\n",
       "     w2v_99  \n",
       "0 -0.132590  \n",
       "1  0.002357  \n",
       "2 -0.088989  \n",
       "3  0.001450  \n",
       "4 -0.091381  \n",
       "\n",
       "[5 rows x 541 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e101762aa0376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T15:25:05.536648443Z",
     "start_time": "2024-04-21T15:25:05.520446709Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "selected_columns = ['Negative_VADER', 'skewed_hour_dist', 'Weekday', 'Compound_VADER',\n",
    "                    'skewed_week_dist', 'w2v_11', 'Mentions', 'Polarity_TB', 'w2v_27',\n",
    "                    'w2v_53', 'Hour', 'w2v_44', 'w2v_84', 'embedding_16']\n",
    "\n",
    "df = df[selected_columns + ['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559afc3eb5393f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T15:25:05.537764657Z",
     "start_time": "2024-04-21T15:25:05.526960545Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_classifiers(X, y, classifiers, param_distributions, cv_folds=5, n_iter=10):\n",
    "    results = {}\n",
    "    best_models = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), (name.lower().replace(\" \", \"\"), clf)])\n",
    "        search = TuneSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=param_distributions.get(name, {}),\n",
    "            n_trials=n_iter,\n",
    "            cv=cv_folds,\n",
    "            scoring='accuracy',\n",
    "            search_optimization=\"random\",\n",
    "            verbose=1,\n",
    "            random_state=42\n",
    "        )\n",
    "        search.fit(X, y)\n",
    "        best_models[name] = search.best_estimator_\n",
    "        results[name] = search.cv_results_\n",
    "        print(f\"{name} Best Accuracy: {search.best_score_:.2f}\")\n",
    "        print(f\"Best Parameters: {search.best_params_}\")\n",
    "\n",
    "    sorted_models = sorted(best_models.items(), key=lambda x: x[1].score(X, y), reverse=True)[:3]\n",
    "    return results, sorted_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a60216344cd3be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T15:37:19.857546600Z",
     "start_time": "2024-04-21T15:37:19.752594161Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = df.drop(['Target'], axis=1)\n",
    "y = df['Target']\n",
    "X = X.select_dtypes(include=['number'])\n",
    "\n",
    "\n",
    "def objective(trial, classifier_name, model, param_grid):\n",
    "    params = {}\n",
    "    for key, values in param_grid.items():\n",
    "        if isinstance(values, list):\n",
    "            params[key] = trial.suggest_categorical(key, values)\n",
    "        elif isinstance(values, tuple) and len(values) == 3 and values[2] == 'log':\n",
    "            params[key] = trial.suggest_float(key, values[0], values[1], log=True)\n",
    "        elif isinstance(values, tuple):\n",
    "            params[key] = trial.suggest_float(key, values[0], values[1])\n",
    "\n",
    "    clf = model(**params)\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', clf)])\n",
    "    score = cross_val_score(pipeline, X, y, n_jobs=-1, cv=5).mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {'C': (1e-4, 1e4, 'log')},\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    'k-Nearest Neighbors': {'n_neighbors': list(range(1, 21))},\n",
    "    'Decision Tree': {'max_depth': list(range(1, 21))},\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 1]\n",
    "    },\n",
    "    'Naive Bayes': {}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad8cfc9db6fc8165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T20:41:12.911736712Z",
     "start_time": "2024-04-20T20:32:17.973768100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 22:32:17,972] A new study created in memory with name: no-name-b904cb88-d6d5-4733-be45-14e7b8f54682\n",
      "[I 2024-04-20 22:32:19,286] Trial 0 finished with value: 0.76877 and parameters: {'C': 0.07697054909558497}. Best is trial 0 with value: 0.76877.\n",
      "[I 2024-04-20 22:32:20,026] Trial 1 finished with value: 0.7687200000000001 and parameters: {'C': 176.52933623262982}. Best is trial 0 with value: 0.76877.\n",
      "[I 2024-04-20 22:32:20,748] Trial 2 finished with value: 0.7687200000000001 and parameters: {'C': 320.41231258205863}. Best is trial 0 with value: 0.76877.\n",
      "[I 2024-04-20 22:32:21,376] Trial 3 finished with value: 0.7687200000000001 and parameters: {'C': 11.859485372705064}. Best is trial 0 with value: 0.76877.\n",
      "[I 2024-04-20 22:32:21,624] Trial 4 finished with value: 0.7687200000000001 and parameters: {'C': 35.635677321925904}. Best is trial 0 with value: 0.76877.\n",
      "[I 2024-04-20 22:32:21,868] Trial 5 finished with value: 0.76933 and parameters: {'C': 0.0012968098405506075}. Best is trial 5 with value: 0.76933.\n",
      "[I 2024-04-20 22:32:22,102] Trial 6 finished with value: 0.76873 and parameters: {'C': 1.3167985721893651}. Best is trial 5 with value: 0.76933.\n",
      "[I 2024-04-20 22:32:22,339] Trial 7 finished with value: 0.7690600000000001 and parameters: {'C': 0.006016366082428774}. Best is trial 5 with value: 0.76933.\n",
      "[I 2024-04-20 22:32:22,576] Trial 8 finished with value: 0.76945 and parameters: {'C': 0.0014317830412433098}. Best is trial 8 with value: 0.76945.\n",
      "[I 2024-04-20 22:32:22,806] Trial 9 finished with value: 0.7687200000000001 and parameters: {'C': 8651.493692519423}. Best is trial 8 with value: 0.76945.\n",
      "[I 2024-04-20 22:32:22,807] A new study created in memory with name: no-name-46970fc8-12e1-4e29-84e4-97c16f5b1a07\n",
      "[I 2024-04-20 22:32:38,763] Trial 0 finished with value: 0.7869300000000001 and parameters: {'n_estimators': 100, 'max_features': 'log2'}. Best is trial 0 with value: 0.7869300000000001.\n",
      "[I 2024-04-20 22:32:40,588] Trial 1 finished with value: 0.76634 and parameters: {'n_estimators': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.7869300000000001.\n",
      "[I 2024-04-20 22:32:48,641] Trial 2 finished with value: 0.7842800000000001 and parameters: {'n_estimators': 50, 'max_features': 'log2'}. Best is trial 0 with value: 0.7869300000000001.\n",
      "[I 2024-04-20 22:33:04,557] Trial 3 finished with value: 0.7873699999999999 and parameters: {'n_estimators': 100, 'max_features': 'log2'}. Best is trial 3 with value: 0.7873699999999999.\n",
      "[I 2024-04-20 22:33:36,285] Trial 4 finished with value: 0.7893200000000001 and parameters: {'n_estimators': 200, 'max_features': 'log2'}. Best is trial 4 with value: 0.7893200000000001.\n",
      "[I 2024-04-20 22:33:44,456] Trial 5 finished with value: 0.78591 and parameters: {'n_estimators': 50, 'max_features': 'log2'}. Best is trial 4 with value: 0.7893200000000001.\n",
      "[I 2024-04-20 22:33:52,556] Trial 6 finished with value: 0.78591 and parameters: {'n_estimators': 50, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.7893200000000001.\n",
      "[I 2024-04-20 22:33:54,320] Trial 7 finished with value: 0.7663599999999999 and parameters: {'n_estimators': 10, 'max_features': 'log2'}. Best is trial 4 with value: 0.7893200000000001.\n",
      "[I 2024-04-20 22:34:26,354] Trial 8 finished with value: 0.78891 and parameters: {'n_estimators': 200, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.7893200000000001.\n",
      "[I 2024-04-20 22:34:28,169] Trial 9 finished with value: 0.7668100000000001 and parameters: {'n_estimators': 10, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.7893200000000001.\n",
      "[I 2024-04-20 22:34:28,170] A new study created in memory with name: no-name-09eeff99-610f-400e-8613-008efe5288dc\n",
      "[I 2024-04-20 22:34:46,297] Trial 0 finished with value: 0.75438 and parameters: {'n_neighbors': 6}. Best is trial 0 with value: 0.75438.\n",
      "[I 2024-04-20 22:35:09,757] Trial 1 finished with value: 0.77329 and parameters: {'n_neighbors': 15}. Best is trial 1 with value: 0.77329.\n",
      "[I 2024-04-20 22:35:27,032] Trial 2 finished with value: 0.7561 and parameters: {'n_neighbors': 5}. Best is trial 1 with value: 0.77329.\n",
      "[I 2024-04-20 22:35:47,812] Trial 3 finished with value: 0.76584 and parameters: {'n_neighbors': 10}. Best is trial 1 with value: 0.77329.\n",
      "[I 2024-04-20 22:36:10,311] Trial 4 finished with value: 0.7721600000000001 and parameters: {'n_neighbors': 13}. Best is trial 1 with value: 0.77329.\n",
      "[I 2024-04-20 22:36:26,606] Trial 5 finished with value: 0.73985 and parameters: {'n_neighbors': 4}. Best is trial 1 with value: 0.77329.\n",
      "[I 2024-04-20 22:36:44,725] Trial 6 finished with value: 0.75438 and parameters: {'n_neighbors': 6}. Best is trial 1 with value: 0.77329.\n",
      "[I 2024-04-20 22:37:09,571] Trial 7 finished with value: 0.77472 and parameters: {'n_neighbors': 20}. Best is trial 7 with value: 0.77472.\n",
      "[I 2024-04-20 22:37:33,638] Trial 8 finished with value: 0.7740799999999999 and parameters: {'n_neighbors': 17}. Best is trial 7 with value: 0.77472.\n",
      "[I 2024-04-20 22:37:55,901] Trial 9 finished with value: 0.7721600000000001 and parameters: {'n_neighbors': 13}. Best is trial 7 with value: 0.77472.\n",
      "[I 2024-04-20 22:37:55,902] A new study created in memory with name: no-name-cb48de79-e9cf-48b9-beeb-f2bbd3421bba\n",
      "[I 2024-04-20 22:37:56,259] Trial 0 finished with value: 0.71198 and parameters: {'max_depth': 2}. Best is trial 0 with value: 0.71198.\n",
      "[I 2024-04-20 22:37:57,258] Trial 1 finished with value: 0.7522599999999999 and parameters: {'max_depth': 14}. Best is trial 1 with value: 0.7522599999999999.\n",
      "[I 2024-04-20 22:37:58,080] Trial 2 finished with value: 0.7688200000000001 and parameters: {'max_depth': 10}. Best is trial 2 with value: 0.7688200000000001.\n",
      "[I 2024-04-20 22:37:58,987] Trial 3 finished with value: 0.76144 and parameters: {'max_depth': 12}. Best is trial 2 with value: 0.7688200000000001.\n",
      "[I 2024-04-20 22:38:00,046] Trial 4 finished with value: 0.74169 and parameters: {'max_depth': 16}. Best is trial 2 with value: 0.7688200000000001.\n",
      "[I 2024-04-20 22:38:00,961] Trial 5 finished with value: 0.76137 and parameters: {'max_depth': 12}. Best is trial 2 with value: 0.7688200000000001.\n",
      "[I 2024-04-20 22:38:02,104] Trial 6 finished with value: 0.72475 and parameters: {'max_depth': 20}. Best is trial 2 with value: 0.7688200000000001.\n",
      "[I 2024-04-20 22:38:02,967] Trial 7 finished with value: 0.7650699999999999 and parameters: {'max_depth': 11}. Best is trial 2 with value: 0.7688200000000001.\n",
      "[I 2024-04-20 22:38:04,079] Trial 8 finished with value: 0.7327999999999999 and parameters: {'max_depth': 18}. Best is trial 2 with value: 0.7688200000000001.\n",
      "[I 2024-04-20 22:38:04,688] Trial 9 finished with value: 0.76237 and parameters: {'max_depth': 6}. Best is trial 2 with value: 0.7688200000000001.\n",
      "[I 2024-04-20 22:38:04,689] A new study created in memory with name: no-name-6113ae03-6e7c-44c5-b3dc-0e5655c362e6\n",
      "[I 2024-04-20 22:38:07,037] Trial 0 finished with value: 0.7572000000000001 and parameters: {'n_estimators': 10, 'learning_rate': 0.1}. Best is trial 0 with value: 0.7572000000000001.\n",
      "[I 2024-04-20 22:38:51,333] Trial 1 finished with value: 0.74003 and parameters: {'n_estimators': 200, 'learning_rate': 0.001}. Best is trial 0 with value: 0.7572000000000001.\n",
      "[I 2024-04-20 22:39:02,630] Trial 2 finished with value: 0.74393 and parameters: {'n_estimators': 50, 'learning_rate': 0.01}. Best is trial 0 with value: 0.7572000000000001.\n",
      "[I 2024-04-20 22:39:05,038] Trial 3 finished with value: 0.73162 and parameters: {'n_estimators': 10, 'learning_rate': 0.001}. Best is trial 0 with value: 0.7572000000000001.\n",
      "[I 2024-04-20 22:39:07,441] Trial 4 finished with value: 0.7572000000000001 and parameters: {'n_estimators': 10, 'learning_rate': 0.1}. Best is trial 0 with value: 0.7572000000000001.\n",
      "[I 2024-04-20 22:39:18,825] Trial 5 finished with value: 0.74393 and parameters: {'n_estimators': 50, 'learning_rate': 0.01}. Best is trial 0 with value: 0.7572000000000001.\n",
      "[I 2024-04-20 22:39:30,180] Trial 6 finished with value: 0.7892399999999999 and parameters: {'n_estimators': 50, 'learning_rate': 1}. Best is trial 6 with value: 0.7892399999999999.\n",
      "[I 2024-04-20 22:40:14,678] Trial 7 finished with value: 0.7853399999999999 and parameters: {'n_estimators': 200, 'learning_rate': 1}. Best is trial 6 with value: 0.7892399999999999.\n",
      "[I 2024-04-20 22:40:59,467] Trial 8 finished with value: 0.78535 and parameters: {'n_estimators': 200, 'learning_rate': 1}. Best is trial 6 with value: 0.7892399999999999.\n",
      "[I 2024-04-20 22:41:10,793] Trial 9 finished with value: 0.78922 and parameters: {'n_estimators': 50, 'learning_rate': 1}. Best is trial 6 with value: 0.7892399999999999.\n",
      "[I 2024-04-20 22:41:10,794] A new study created in memory with name: no-name-3ed8f322-44b7-4397-b37e-decccf7c970a\n",
      "[I 2024-04-20 22:41:11,009] Trial 0 finished with value: 0.75135 and parameters: {}. Best is trial 0 with value: 0.75135.\n",
      "[I 2024-04-20 22:41:11,225] Trial 1 finished with value: 0.75135 and parameters: {}. Best is trial 0 with value: 0.75135.\n",
      "[I 2024-04-20 22:41:11,437] Trial 2 finished with value: 0.75135 and parameters: {}. Best is trial 0 with value: 0.75135.\n",
      "[I 2024-04-20 22:41:11,643] Trial 3 finished with value: 0.75135 and parameters: {}. Best is trial 0 with value: 0.75135.\n",
      "[I 2024-04-20 22:41:11,851] Trial 4 finished with value: 0.75135 and parameters: {}. Best is trial 0 with value: 0.75135.\n",
      "[I 2024-04-20 22:41:12,068] Trial 5 finished with value: 0.75135 and parameters: {}. Best is trial 0 with value: 0.75135.\n",
      "[I 2024-04-20 22:41:12,278] Trial 6 finished with value: 0.75135 and parameters: {}. Best is trial 0 with value: 0.75135.\n",
      "[I 2024-04-20 22:41:12,484] Trial 7 finished with value: 0.75135 and parameters: {}. Best is trial 0 with value: 0.75135.\n",
      "[I 2024-04-20 22:41:12,694] Trial 8 finished with value: 0.75135 and parameters: {}. Best is trial 0 with value: 0.75135.\n",
      "[I 2024-04-20 22:41:12,907] Trial 9 finished with value: 0.75135 and parameters: {}. Best is trial 0 with value: 0.75135.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Best Score: 0.7694\n",
      "Best Parameters: {'C': 0.0014317830412433098}\n",
      "Random Forest - Best Score: 0.7893\n",
      "Best Parameters: {'n_estimators': 200, 'max_features': 'log2'}\n",
      "k-Nearest Neighbors - Best Score: 0.7747\n",
      "Best Parameters: {'n_neighbors': 20}\n",
      "Decision Tree - Best Score: 0.7688\n",
      "Best Parameters: {'max_depth': 10}\n",
      "Gradient Boosting - Best Score: 0.7892\n",
      "Best Parameters: {'n_estimators': 50, 'learning_rate': 1}\n",
      "Naive Bayes - Best Score: 0.7513\n",
      "Best Parameters: {}\n"
     ]
    }
   ],
   "source": [
    "study_results = {}\n",
    "for name, grid in param_grids.items():\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, name, {\n",
    "        'Logistic Regression': LogisticRegression,\n",
    "        'Random Forest': RandomForestClassifier,\n",
    "        'k-Nearest Neighbors': KNeighborsClassifier,\n",
    "        'Decision Tree': DecisionTreeClassifier,\n",
    "        'Gradient Boosting': GradientBoostingClassifier,\n",
    "        'Naive Bayes': GaussianNB\n",
    "    }[name], grid), n_trials=10)\n",
    "\n",
    "    study_results[name] = {\n",
    "        'Best Score': study.best_value,\n",
    "        'Best Parameters': study.best_params\n",
    "    }\n",
    "\n",
    "for classifier, result in study_results.items():\n",
    "    print(f\"{classifier} - Best Score: {result['Best Score']:.4f}\")\n",
    "    print(f\"Best Parameters: {result['Best Parameters']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec768c46a63652f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T15:37:04.034955257Z",
     "start_time": "2024-04-21T15:37:03.921122424Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_ensemble_classifiers(X, y, classifiers, cv_folds=5):\n",
    "    results = {}\n",
    "    for name, model in classifiers.items():\n",
    "        cv_scores = cross_val_score(model, X, y, cv=cv_folds, scoring='accuracy')\n",
    "        results[name] = {\n",
    "            'Mean Accuracy': np.mean(cv_scores),\n",
    "            'Standard Deviation': np.std(cv_scores),\n",
    "            'All Scores': cv_scores\n",
    "        }\n",
    "        print(f\"{name}: Mean Accuracy = {results[name]['Mean Accuracy']:.4f}, \" +\n",
    "              f\"Std Deviation = {results[name]['Standard Deviation']:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd1cd5a28d84fbf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T15:41:40.979665457Z",
     "start_time": "2024-04-21T15:37:33.960909302Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting_Soft: Mean Accuracy = 0.7842, Std Deviation = 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost (with Decision Tree): Mean Accuracy = 0.7317, Std Deviation = 0.0015\n",
      "Bagging (with Logistic Regression): Mean Accuracy = 0.7573, Std Deviation = 0.0025\n",
      "Stacking: Mean Accuracy = 0.7756, Std Deviation = 0.0026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, \\\n",
    "    StackingClassifier, VotingClassifier\n",
    "\n",
    "base_estimators = [\n",
    "    ('DecisionTree', DecisionTreeClassifier(max_depth=10)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=20)),\n",
    "    ('LogisticRegression', LogisticRegression(C=0.0014, max_iter=1000))\n",
    "]\n",
    "\n",
    "\n",
    "ensemble_classifiers = {\n",
    "    \"Voting_Soft\": VotingClassifier(estimators=base_estimators, voting='soft'),\n",
    "    \"AdaBoost (with Decision Tree)\": AdaBoostClassifier(DecisionTreeClassifier(max_depth=10), n_estimators=50),\n",
    "    \"Bagging (with Logistic Regression)\": BaggingClassifier(LogisticRegression(C=0.0014, max_iter=1000), n_estimators=10),\n",
    "    \"Stacking\": StackingClassifier(estimators=base_estimators, final_estimator=GradientBoostingClassifier(n_estimators=50, learning_rate=1))\n",
    "}\n",
    "\n",
    "ensemble_classifiers_res = evaluate_ensemble_classifiers(X, y, ensemble_classifiers, cv_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690ffe50669f7f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T15:42:03.427684142Z",
     "start_time": "2024-04-21T15:42:02.862105283Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77585"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "model = XGBClassifier(random_state=1,\n",
    "                      learning_rate=0.01,\n",
    "                      booster='gbtree',\n",
    "                      max_depth=5\n",
    "                      )\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3854cb8d91bfd33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T15:47:59.979961052Z",
     "start_time": "2024-04-21T15:46:44.792639555Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 544us/step - accuracy: 0.7396 - loss: 0.5166 - val_accuracy: 0.7729 - val_loss: 0.4695\n",
      "Epoch 2/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.7700 - loss: 0.4692 - val_accuracy: 0.7789 - val_loss: 0.4521\n",
      "Epoch 3/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.7787 - loss: 0.4540 - val_accuracy: 0.7808 - val_loss: 0.4447\n",
      "Epoch 4/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.7797 - loss: 0.4516 - val_accuracy: 0.7820 - val_loss: 0.4407\n",
      "Epoch 5/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step - accuracy: 0.7827 - loss: 0.4429 - val_accuracy: 0.7847 - val_loss: 0.4380\n",
      "Epoch 6/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7859 - loss: 0.4391 - val_accuracy: 0.7861 - val_loss: 0.4409\n",
      "Epoch 7/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.7861 - loss: 0.4371 - val_accuracy: 0.7883 - val_loss: 0.4330\n",
      "Epoch 8/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517us/step - accuracy: 0.7864 - loss: 0.4384 - val_accuracy: 0.7901 - val_loss: 0.4319\n",
      "Epoch 9/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515us/step - accuracy: 0.7861 - loss: 0.4358 - val_accuracy: 0.7906 - val_loss: 0.4292\n",
      "Epoch 10/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - accuracy: 0.7880 - loss: 0.4342 - val_accuracy: 0.7931 - val_loss: 0.4293\n",
      "Epoch 11/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.7900 - loss: 0.4292 - val_accuracy: 0.7912 - val_loss: 0.4293\n",
      "Epoch 12/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.7903 - loss: 0.4295 - val_accuracy: 0.7894 - val_loss: 0.4295\n",
      "Epoch 13/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.7905 - loss: 0.4285 - val_accuracy: 0.7940 - val_loss: 0.4254\n",
      "Epoch 14/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 468us/step - accuracy: 0.7900 - loss: 0.4266 - val_accuracy: 0.7936 - val_loss: 0.4239\n",
      "Epoch 15/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - accuracy: 0.7897 - loss: 0.4294 - val_accuracy: 0.7946 - val_loss: 0.4228\n",
      "Epoch 16/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473us/step - accuracy: 0.7942 - loss: 0.4248 - val_accuracy: 0.7940 - val_loss: 0.4211\n",
      "Epoch 17/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476us/step - accuracy: 0.7936 - loss: 0.4212 - val_accuracy: 0.7933 - val_loss: 0.4236\n",
      "Epoch 18/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - accuracy: 0.7929 - loss: 0.4220 - val_accuracy: 0.7918 - val_loss: 0.4273\n",
      "Epoch 19/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 656us/step - accuracy: 0.7971 - loss: 0.4189 - val_accuracy: 0.7936 - val_loss: 0.4221\n",
      "Epoch 20/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 835us/step - accuracy: 0.7923 - loss: 0.4236 - val_accuracy: 0.7958 - val_loss: 0.4221\n",
      "Epoch 21/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514us/step - accuracy: 0.7923 - loss: 0.4222 - val_accuracy: 0.7957 - val_loss: 0.4204\n",
      "Epoch 22/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - accuracy: 0.7921 - loss: 0.4227 - val_accuracy: 0.7929 - val_loss: 0.4254\n",
      "Epoch 23/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.7960 - loss: 0.4196 - val_accuracy: 0.7932 - val_loss: 0.4252\n",
      "Epoch 24/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.7942 - loss: 0.4207 - val_accuracy: 0.7943 - val_loss: 0.4218\n",
      "Epoch 25/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.7914 - loss: 0.4198 - val_accuracy: 0.7945 - val_loss: 0.4247\n",
      "Epoch 26/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.7970 - loss: 0.4172 - val_accuracy: 0.7925 - val_loss: 0.4259\n",
      "Epoch 27/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.7957 - loss: 0.4179 - val_accuracy: 0.7957 - val_loss: 0.4201\n",
      "Epoch 28/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.7961 - loss: 0.4176 - val_accuracy: 0.7950 - val_loss: 0.4229\n",
      "Epoch 29/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530us/step - accuracy: 0.7943 - loss: 0.4197 - val_accuracy: 0.7948 - val_loss: 0.4244\n",
      "Epoch 30/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 805us/step - accuracy: 0.7942 - loss: 0.4173 - val_accuracy: 0.7934 - val_loss: 0.4229\n",
      "Epoch 31/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 604us/step - accuracy: 0.7963 - loss: 0.4171 - val_accuracy: 0.7972 - val_loss: 0.4210\n",
      "Epoch 32/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 673us/step - accuracy: 0.7967 - loss: 0.4147 - val_accuracy: 0.7922 - val_loss: 0.4243\n",
      "Epoch 33/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736us/step - accuracy: 0.7971 - loss: 0.4125 - val_accuracy: 0.7958 - val_loss: 0.4222\n",
      "Epoch 34/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 788us/step - accuracy: 0.7998 - loss: 0.4141 - val_accuracy: 0.7943 - val_loss: 0.4207\n",
      "Epoch 35/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 817us/step - accuracy: 0.7940 - loss: 0.4182 - val_accuracy: 0.7883 - val_loss: 0.4343\n",
      "Epoch 36/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 986us/step - accuracy: 0.7976 - loss: 0.4129 - val_accuracy: 0.7951 - val_loss: 0.4235\n",
      "Epoch 37/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 695us/step - accuracy: 0.7964 - loss: 0.4153 - val_accuracy: 0.7954 - val_loss: 0.4244\n",
      "Epoch 38/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.7981 - loss: 0.4108 - val_accuracy: 0.7942 - val_loss: 0.4247\n",
      "Epoch 39/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - accuracy: 0.7997 - loss: 0.4114 - val_accuracy: 0.7924 - val_loss: 0.4255\n",
      "Epoch 40/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - accuracy: 0.8002 - loss: 0.4084 - val_accuracy: 0.7930 - val_loss: 0.4264\n",
      "Epoch 41/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 620us/step - accuracy: 0.7984 - loss: 0.4115 - val_accuracy: 0.7939 - val_loss: 0.4242\n",
      "Epoch 42/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.7986 - loss: 0.4107 - val_accuracy: 0.7944 - val_loss: 0.4238\n",
      "Epoch 43/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496us/step - accuracy: 0.7986 - loss: 0.4100 - val_accuracy: 0.7934 - val_loss: 0.4267\n",
      "Epoch 44/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517us/step - accuracy: 0.7991 - loss: 0.4118 - val_accuracy: 0.7933 - val_loss: 0.4265\n",
      "Epoch 45/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.7993 - loss: 0.4122 - val_accuracy: 0.7890 - val_loss: 0.4314\n",
      "Epoch 46/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - accuracy: 0.8001 - loss: 0.4094 - val_accuracy: 0.7914 - val_loss: 0.4291\n",
      "Epoch 47/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 657us/step - accuracy: 0.8009 - loss: 0.4094 - val_accuracy: 0.7917 - val_loss: 0.4254\n",
      "Epoch 48/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 518us/step - accuracy: 0.8012 - loss: 0.4082 - val_accuracy: 0.7933 - val_loss: 0.4248\n",
      "Epoch 49/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 695us/step - accuracy: 0.7976 - loss: 0.4113 - val_accuracy: 0.7930 - val_loss: 0.4245\n",
      "Epoch 50/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.7993 - loss: 0.4087 - val_accuracy: 0.7900 - val_loss: 0.4301\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-4 * 10**( -(epoch // 10))\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', activity_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f14b4c95e98595e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
