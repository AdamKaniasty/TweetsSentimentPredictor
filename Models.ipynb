{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T12:18:30.455540483Z",
     "start_time": "2024-04-19T12:18:29.806463184Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/tweets_features.csv\", encoding='latin')\n",
    "df.drop(['is_after_certain_day', 'Date', 'User', 'Text', 'Time', 'Full_date'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T12:18:43.701658751Z",
     "start_time": "2024-04-19T12:18:30.455423043Z"
    }
   },
   "id": "51d04b62db515eba",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Target  Weekday  Length  Hashtags  HasHashtags  Mentions  HasMentions  \\\n0       0        3      67         0        False         1         True   \n1       1        3      93         0        False         1         True   \n2       1        0      27         0        False         0        False   \n3       0        3     100         0        False         0        False   \n4       0        4      52         0        False         0        False   \n\n   ExclamationMarks  HasExclamationMarks Emoticons  ...    w2v_90    w2v_91  \\\n0                 0                False        []  ...  0.426355  0.105600   \n1                 0                False        []  ...  0.893100  0.385402   \n2                 1                 True        []  ...  0.590157  0.242431   \n3                 0                False        []  ...  0.741138  0.014045   \n4                 1                 True        []  ...  0.621242  0.201937   \n\n     w2v_92    w2v_93    w2v_94    w2v_95    w2v_96    w2v_97    w2v_98  \\\n0  0.099900  0.141384  0.683017  0.307975  0.141498 -0.470852 -0.146050   \n1 -0.035950 -0.465414  1.386158  0.869907  0.718067 -0.696911 -0.041971   \n2 -0.339337  0.507457  1.383398  1.200003  0.258323 -0.451583  0.037492   \n3 -0.037039 -0.300930  1.460556  0.542765  0.764829 -0.621368 -0.208227   \n4 -0.061574  0.177444  1.245472  0.712410  0.349455 -0.450614  0.096795   \n\n     w2v_99  \n0  0.013814  \n1 -0.195380  \n2  0.057117  \n3 -0.209104  \n4  0.056020  \n\n[5 rows x 541 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Weekday</th>\n      <th>Length</th>\n      <th>Hashtags</th>\n      <th>HasHashtags</th>\n      <th>Mentions</th>\n      <th>HasMentions</th>\n      <th>ExclamationMarks</th>\n      <th>HasExclamationMarks</th>\n      <th>Emoticons</th>\n      <th>...</th>\n      <th>w2v_90</th>\n      <th>w2v_91</th>\n      <th>w2v_92</th>\n      <th>w2v_93</th>\n      <th>w2v_94</th>\n      <th>w2v_95</th>\n      <th>w2v_96</th>\n      <th>w2v_97</th>\n      <th>w2v_98</th>\n      <th>w2v_99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>67</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>True</td>\n      <td>0</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>0.426355</td>\n      <td>0.105600</td>\n      <td>0.099900</td>\n      <td>0.141384</td>\n      <td>0.683017</td>\n      <td>0.307975</td>\n      <td>0.141498</td>\n      <td>-0.470852</td>\n      <td>-0.146050</td>\n      <td>0.013814</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>93</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>True</td>\n      <td>0</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>0.893100</td>\n      <td>0.385402</td>\n      <td>-0.035950</td>\n      <td>-0.465414</td>\n      <td>1.386158</td>\n      <td>0.869907</td>\n      <td>0.718067</td>\n      <td>-0.696911</td>\n      <td>-0.041971</td>\n      <td>-0.195380</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>27</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>True</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>0.590157</td>\n      <td>0.242431</td>\n      <td>-0.339337</td>\n      <td>0.507457</td>\n      <td>1.383398</td>\n      <td>1.200003</td>\n      <td>0.258323</td>\n      <td>-0.451583</td>\n      <td>0.037492</td>\n      <td>0.057117</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>100</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>0.741138</td>\n      <td>0.014045</td>\n      <td>-0.037039</td>\n      <td>-0.300930</td>\n      <td>1.460556</td>\n      <td>0.542765</td>\n      <td>0.764829</td>\n      <td>-0.621368</td>\n      <td>-0.208227</td>\n      <td>-0.209104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>52</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>True</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>0.621242</td>\n      <td>0.201937</td>\n      <td>-0.061574</td>\n      <td>0.177444</td>\n      <td>1.245472</td>\n      <td>0.712410</td>\n      <td>0.349455</td>\n      <td>-0.450614</td>\n      <td>0.096795</td>\n      <td>0.056020</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 541 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T12:18:43.718243900Z",
     "start_time": "2024-04-19T12:18:43.705081876Z"
    }
   },
   "id": "87ed935cc58ad477",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "selected_columns = ['Compound_VADER', 'skewed_hour_dist', 'Negative_VADER', 'Weekday',\n",
    "                    'Polarity_TB', 'skewed_week_dist', 'Neutral_VADER', 'embedding_166',\n",
    "                    'embedding_22', 'embedding_91', 'embedding_299', 'embedding_340',\n",
    "                    'embedding_34', 'embedding_93', 'embedding_231', 'embedding_156',\n",
    "                    'has_mentions', 'embedding_144', 'w2v_2', 'embedding_189',\n",
    "                    'embedding_33']\n",
    "\n",
    "df = df[selected_columns + ['Target']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T12:18:43.744042252Z",
     "start_time": "2024-04-19T12:18:43.717705139Z"
    }
   },
   "id": "46e101762aa0376",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def evaluate_classifiers(X, y, classifiers, cv_folds):\n",
    "    results = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        scores = cross_val_score(clf, X, y, cv=cv_folds)\n",
    "        results[name] = scores\n",
    "        print(f\"{name} Accuracy: {np.mean(scores):.2f} (+/- {np.std(scores) * 2:.2f})\")\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T12:18:44.251143253Z",
     "start_time": "2024-04-19T12:18:43.725162807Z"
    }
   },
   "id": "559afc3eb5393f25",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(['Target'], axis=1)\n",
    "y = df['Target']\n",
    "X = X.select_dtypes(include=['number'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"SVM\": SVC(),\n",
    "    \"k-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T12:18:44.364845533Z",
     "start_time": "2024-04-19T12:18:44.253030074Z"
    }
   },
   "id": "7a60216344cd3be3",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.82 (+/- 0.00)\n",
      "Random Forest Accuracy: 0.83 (+/- 0.00)\n",
      "SVM Accuracy: 0.82 (+/- 0.00)\n",
      "k-Nearest Neighbors Accuracy: 0.78 (+/- 0.00)\n",
      "Decision Tree Accuracy: 0.76 (+/- 0.00)\n",
      "Gradient Boosting Accuracy: 0.82 (+/- 0.00)\n",
      "Naive Bayes Accuracy: 0.78 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "basic_classifiers_res = evaluate_classifiers(X, y, classifiers, cv_folds=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T12:45:41.699462818Z",
     "start_time": "2024-04-19T12:18:44.366896813Z"
    }
   },
   "id": "ad8cfc9db6fc8165",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting_Soft Accuracy: 0.80 (+/- 0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/adam/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.82 (+/- 0.00)\n",
      "Bagging (with Decision Tree) Accuracy: 0.82 (+/- 0.00)\n",
      "Stacking Accuracy: 0.83 (+/- 0.00)\n",
      "Gradient Boosting Accuracy: 0.82 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, \\\n",
    "    StackingClassifier, VotingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('DecisionTree', DecisionTreeClassifier()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('RandomForest', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "ensemble_classifiers = {\n",
    "    \"Voting_Soft\": VotingClassifier(estimators=estimators, voting='soft'),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"Bagging (with Logistic Regression)\": BaggingClassifier(LogisticRegression(max_iter=1000), n_estimators=10),\n",
    "    \"Stacking\": StackingClassifier(estimators=estimators, final_estimator=LogisticRegression()),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "ensemble_classifiers_res = evaluate_classifiers(X, y, ensemble_classifiers, cv_folds=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T13:04:26.621801309Z",
     "start_time": "2024-04-19T12:45:41.699360967Z"
    }
   },
   "id": "cd1cd5a28d84fbf8",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.79505"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "model=XGBClassifier(random_state=1,\n",
    "                    learning_rate=0.01,\n",
    "                    booster='gbtree',\n",
    "                    max_depth=4\n",
    "                    )\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T13:04:27.742050844Z",
     "start_time": "2024-04-19T13:04:26.619532020Z"
    }
   },
   "id": "690ffe50669f7f3b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 15:04:28.532973: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-19 15:04:29.643378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 726us/step - accuracy: 0.8092 - loss: 0.4059 - val_accuracy: 0.8232 - val_loss: 0.3837\n",
      "Epoch 2/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 684us/step - accuracy: 0.8201 - loss: 0.3813 - val_accuracy: 0.8235 - val_loss: 0.3819\n",
      "Epoch 3/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 656us/step - accuracy: 0.8233 - loss: 0.3755 - val_accuracy: 0.8256 - val_loss: 0.3802\n",
      "Epoch 4/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 657us/step - accuracy: 0.8259 - loss: 0.3678 - val_accuracy: 0.8283 - val_loss: 0.3759\n",
      "Epoch 5/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 648us/step - accuracy: 0.8298 - loss: 0.3652 - val_accuracy: 0.8264 - val_loss: 0.3758\n",
      "Epoch 6/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 662us/step - accuracy: 0.8287 - loss: 0.3610 - val_accuracy: 0.8252 - val_loss: 0.3771\n",
      "Epoch 7/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 660us/step - accuracy: 0.8290 - loss: 0.3599 - val_accuracy: 0.8234 - val_loss: 0.3763\n",
      "Epoch 8/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 656us/step - accuracy: 0.8314 - loss: 0.3592 - val_accuracy: 0.8282 - val_loss: 0.3723\n",
      "Epoch 9/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 651us/step - accuracy: 0.8327 - loss: 0.3568 - val_accuracy: 0.8264 - val_loss: 0.3753\n",
      "Epoch 10/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 694us/step - accuracy: 0.8335 - loss: 0.3550 - val_accuracy: 0.8285 - val_loss: 0.3729\n",
      "Epoch 11/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 639us/step - accuracy: 0.8348 - loss: 0.3519 - val_accuracy: 0.8253 - val_loss: 0.3767\n",
      "Epoch 12/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 666us/step - accuracy: 0.8350 - loss: 0.3508 - val_accuracy: 0.8260 - val_loss: 0.3757\n",
      "Epoch 13/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 653us/step - accuracy: 0.8378 - loss: 0.3484 - val_accuracy: 0.8250 - val_loss: 0.3766\n",
      "Epoch 14/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 659us/step - accuracy: 0.8363 - loss: 0.3489 - val_accuracy: 0.8257 - val_loss: 0.3778\n",
      "Epoch 15/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 659us/step - accuracy: 0.8376 - loss: 0.3473 - val_accuracy: 0.8245 - val_loss: 0.3766\n",
      "Epoch 16/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 643us/step - accuracy: 0.8387 - loss: 0.3466 - val_accuracy: 0.8253 - val_loss: 0.3788\n",
      "Epoch 17/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 632us/step - accuracy: 0.8381 - loss: 0.3450 - val_accuracy: 0.8249 - val_loss: 0.3807\n",
      "Epoch 18/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 644us/step - accuracy: 0.8431 - loss: 0.3389 - val_accuracy: 0.8239 - val_loss: 0.3815\n",
      "Epoch 19/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 646us/step - accuracy: 0.8409 - loss: 0.3417 - val_accuracy: 0.8224 - val_loss: 0.3816\n",
      "Epoch 20/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 656us/step - accuracy: 0.8414 - loss: 0.3409 - val_accuracy: 0.8246 - val_loss: 0.3816\n",
      "Epoch 21/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 631us/step - accuracy: 0.8428 - loss: 0.3385 - val_accuracy: 0.8225 - val_loss: 0.3867\n",
      "Epoch 22/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 651us/step - accuracy: 0.8438 - loss: 0.3374 - val_accuracy: 0.8231 - val_loss: 0.3852\n",
      "Epoch 23/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 640us/step - accuracy: 0.8435 - loss: 0.3359 - val_accuracy: 0.8228 - val_loss: 0.3880\n",
      "Epoch 24/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 635us/step - accuracy: 0.8455 - loss: 0.3346 - val_accuracy: 0.8222 - val_loss: 0.3873\n",
      "Epoch 25/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 637us/step - accuracy: 0.8475 - loss: 0.3301 - val_accuracy: 0.8213 - val_loss: 0.3881\n",
      "Epoch 26/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 641us/step - accuracy: 0.8486 - loss: 0.3292 - val_accuracy: 0.8184 - val_loss: 0.3897\n",
      "Epoch 27/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 636us/step - accuracy: 0.8460 - loss: 0.3324 - val_accuracy: 0.8214 - val_loss: 0.3872\n",
      "Epoch 28/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 665us/step - accuracy: 0.8492 - loss: 0.3279 - val_accuracy: 0.8155 - val_loss: 0.3937\n",
      "Epoch 29/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 635us/step - accuracy: 0.8495 - loss: 0.3293 - val_accuracy: 0.8169 - val_loss: 0.3914\n",
      "Epoch 30/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 640us/step - accuracy: 0.8491 - loss: 0.3269 - val_accuracy: 0.8157 - val_loss: 0.3982\n",
      "Epoch 31/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 653us/step - accuracy: 0.8514 - loss: 0.3248 - val_accuracy: 0.8187 - val_loss: 0.3949\n",
      "Epoch 32/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 633us/step - accuracy: 0.8503 - loss: 0.3223 - val_accuracy: 0.8190 - val_loss: 0.3954\n",
      "Epoch 33/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 643us/step - accuracy: 0.8510 - loss: 0.3248 - val_accuracy: 0.8181 - val_loss: 0.3934\n",
      "Epoch 34/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 633us/step - accuracy: 0.8497 - loss: 0.3233 - val_accuracy: 0.8183 - val_loss: 0.3936\n",
      "Epoch 35/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 639us/step - accuracy: 0.8519 - loss: 0.3233 - val_accuracy: 0.8146 - val_loss: 0.4000\n",
      "Epoch 36/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 642us/step - accuracy: 0.8521 - loss: 0.3229 - val_accuracy: 0.8196 - val_loss: 0.4012\n",
      "Epoch 37/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 633us/step - accuracy: 0.8526 - loss: 0.3221 - val_accuracy: 0.8163 - val_loss: 0.4009\n",
      "Epoch 38/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 631us/step - accuracy: 0.8521 - loss: 0.3198 - val_accuracy: 0.8195 - val_loss: 0.3986\n",
      "Epoch 39/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 644us/step - accuracy: 0.8543 - loss: 0.3199 - val_accuracy: 0.8177 - val_loss: 0.4041\n",
      "Epoch 40/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 642us/step - accuracy: 0.8546 - loss: 0.3162 - val_accuracy: 0.8171 - val_loss: 0.4026\n",
      "Epoch 41/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 646us/step - accuracy: 0.8526 - loss: 0.3207 - val_accuracy: 0.8192 - val_loss: 0.4007\n",
      "Epoch 42/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 638us/step - accuracy: 0.8537 - loss: 0.3196 - val_accuracy: 0.8188 - val_loss: 0.4041\n",
      "Epoch 43/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 653us/step - accuracy: 0.8545 - loss: 0.3173 - val_accuracy: 0.8167 - val_loss: 0.4031\n",
      "Epoch 44/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 640us/step - accuracy: 0.8552 - loss: 0.3179 - val_accuracy: 0.8149 - val_loss: 0.4045\n",
      "Epoch 45/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 674us/step - accuracy: 0.8520 - loss: 0.3188 - val_accuracy: 0.8131 - val_loss: 0.4087\n",
      "Epoch 46/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 635us/step - accuracy: 0.8572 - loss: 0.3144 - val_accuracy: 0.8188 - val_loss: 0.4042\n",
      "Epoch 47/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 647us/step - accuracy: 0.8544 - loss: 0.3169 - val_accuracy: 0.8181 - val_loss: 0.4056\n",
      "Epoch 48/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 654us/step - accuracy: 0.8577 - loss: 0.3160 - val_accuracy: 0.8162 - val_loss: 0.4096\n",
      "Epoch 49/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 638us/step - accuracy: 0.8602 - loss: 0.3112 - val_accuracy: 0.8153 - val_loss: 0.4091\n",
      "Epoch 50/50\n",
      "\u001B[1m2500/2500\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 656us/step - accuracy: 0.8546 - loss: 0.3161 - val_accuracy: 0.8157 - val_loss: 0.4107\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, epochs=50, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T13:05:53.421963140Z",
     "start_time": "2024-04-19T13:04:27.745641444Z"
    }
   },
   "id": "b3854cb8d91bfd33",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T13:05:53.425700445Z",
     "start_time": "2024-04-19T13:05:53.422414167Z"
    }
   },
   "id": "dbeacb3bff7de39d",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
