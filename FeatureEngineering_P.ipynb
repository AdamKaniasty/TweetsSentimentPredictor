{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:48:08.923069430Z",
     "start_time": "2024-03-26T12:48:08.913409489Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/tweets.csv\", encoding='latin')\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%a %b %d %H:%M:%S PDT %Y')\n",
    "df = df[df['Date'] < pd.Timestamp('2009-05-28')]\n",
    "# df = df.head(50)\n",
    "\n",
    "try:\n",
    "    df.drop(['ID', 'flag'], axis=1, inplace=True)\n",
    "except KeyError:\n",
    "    pass\n",
    "df['Weekday'] = df['Date'].dt.weekday\n",
    "df['Time'] = df['Date'].dt.time\n",
    "df['Full_date'] = df['Date'].dt.date\n",
    "\n",
    "df['Target'] = df['Target'].map({0: 0, 4: 1})\n",
    "df['Length'] = df['Text'].apply(len)\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def count_hashtags(text):\n",
    "    return len([c for c in text if c == '#'])\n",
    "\n",
    "\n",
    "def count_mentions(text):\n",
    "    return len([c for c in text if c == '@'])\n",
    "\n",
    "\n",
    "def count_exclamation_marks(text):\n",
    "    return len([c for c in text if c == '!'])\n",
    "\n",
    "\n",
    "def detect_emoticons(text):\n",
    "    emoticon_pattern = r'(:\\)|:\\(|;\\)|:D|:P|:\\||:\\-\\)|:\\-\\(|;\\-\\)|:‑D|:‑P|:‑\\||<3)'\n",
    "    return re.findall(emoticon_pattern, text)\n",
    "\n",
    "\n",
    "df['Hashtags'] = df['Text'].apply(count_hashtags)\n",
    "df['HasHashtags'] = df['Hashtags'] > 0\n",
    "values_df = pd.DataFrame()\n",
    "values_df['Hashtags'] = df['Hashtags'].value_counts()\n",
    "\n",
    "df['Mentions'] = df['Text'].apply(count_mentions)\n",
    "df['HasMentions'] = df['Mentions'] > 0\n",
    "values_df['Mentions'] = df['Mentions'].value_counts()\n",
    "\n",
    "df['ExclamationMarks'] = df['Text'].apply(count_exclamation_marks)\n",
    "df['HasExclamationMarks'] = df['ExclamationMarks'] > 0\n",
    "values_df['ExclamationMarks'] = df['ExclamationMarks'].value_counts()\n",
    "\n",
    "df['Emoticons'] = df['Text'].apply(detect_emoticons)\n",
    "emoticons = df[['Target', 'Emoticons']].explode('Emoticons').dropna().groupby(['Emoticons']).agg(\n",
    "    ['mean', 'count']).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:48:15.561198087Z",
     "start_time": "2024-03-26T12:48:08.915726575Z"
    }
   },
   "id": "a66dd8c9e895c749",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import textstat\n",
    "df['FRE'] = df['Text'].apply(lambda x: textstat.flesch_reading_ease(x))\n",
    "df['GFI'] = df['Text'].apply(lambda x: textstat.gunning_fog(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:48:40.425047327Z",
     "start_time": "2024-03-26T12:48:15.561851152Z"
    }
   },
   "id": "bdf590a8c9688fc0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def analyze_textblob_sentiment(tweet):\n",
    "    analysis = TextBlob(tweet)\n",
    "    return analysis.sentiment.polarity, analysis.sentiment.subjectivity\n",
    "\n",
    "df[['Polarity_TB', 'Subjectivity_TB']] = df['Text'].apply(lambda tweet: pd.Series(analyze_textblob_sentiment(tweet)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:49:54.683784986Z",
     "start_time": "2024-03-26T12:48:40.464921270Z"
    }
   },
   "id": "6619a374c748e01f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_vader_sentiment(tweet):\n",
    "    scores = sia.polarity_scores(tweet)\n",
    "    return scores['pos'], scores['neu'], scores['neg'], scores['compound']\n",
    "\n",
    "df[['Positive_VADER', 'Neutral_VADER', 'Negative_VADER', 'Compound_VADER']] = df['Text'].apply(lambda tweet: pd.Series(analyze_vader_sentiment(tweet)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:50:56.373234709Z",
     "start_time": "2024-03-26T12:49:54.728510019Z"
    }
   },
   "id": "c1971f294f2b3b0b",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Target                Date           User  \\\n0       0 2009-04-06 22:19:49  scotthamilton   \n1       0 2009-04-06 22:19:53       mattycus   \n2       0 2009-04-06 22:19:57        ElleCTF   \n3       0 2009-04-06 22:19:57         Karoli   \n4       0 2009-04-06 22:20:00       joy_wolf   \n\n                                                Text  Weekday      Time  \\\n0  is upset that he can't update his Facebook by ...        0  22:19:49   \n1  @Kenichan I dived many times for the ball. Man...        0  22:19:53   \n2    my whole body feels itchy and like its on fire         0  22:19:57   \n3  @nationwideclass no, it's not behaving at all....        0  22:19:57   \n4                      @Kwesidei not the whole crew         0  22:20:00   \n\n    Full_date  Length  Hashtags  HasHashtags  ...  HasExclamationMarks  \\\n0  2009-04-06     111         0        False  ...                 True   \n1  2009-04-06      89         0        False  ...                False   \n2  2009-04-06      47         0        False  ...                False   \n3  2009-04-06     111         0        False  ...                False   \n4  2009-04-06      29         0        False  ...                False   \n\n   Emoticons     FRE   GFI Polarity_TB  Subjectivity_TB  Positive_VADER  \\\n0         []   86.20  4.20       0.000              0.0           0.000   \n1         []  104.64  3.60       0.500              0.5           0.167   \n2         []  112.09  4.00       0.200              0.4           0.179   \n3         []   89.75  6.61      -0.625              1.0           0.000   \n4         []  117.16  2.00       0.200              0.4           0.000   \n\n   Neutral_VADER  Negative_VADER  Compound_VADER  \n0          0.697           0.303         -0.7500  \n1          0.833           0.000          0.4939  \n2          0.500           0.321         -0.2500  \n3          0.759           0.241         -0.6597  \n4          1.000           0.000          0.0000  \n\n[5 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Date</th>\n      <th>User</th>\n      <th>Text</th>\n      <th>Weekday</th>\n      <th>Time</th>\n      <th>Full_date</th>\n      <th>Length</th>\n      <th>Hashtags</th>\n      <th>HasHashtags</th>\n      <th>...</th>\n      <th>HasExclamationMarks</th>\n      <th>Emoticons</th>\n      <th>FRE</th>\n      <th>GFI</th>\n      <th>Polarity_TB</th>\n      <th>Subjectivity_TB</th>\n      <th>Positive_VADER</th>\n      <th>Neutral_VADER</th>\n      <th>Negative_VADER</th>\n      <th>Compound_VADER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:49</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>0</td>\n      <td>22:19:49</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>[]</td>\n      <td>86.20</td>\n      <td>4.20</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.697</td>\n      <td>0.303</td>\n      <td>-0.7500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:53</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>0</td>\n      <td>22:19:53</td>\n      <td>2009-04-06</td>\n      <td>89</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>104.64</td>\n      <td>3.60</td>\n      <td>0.500</td>\n      <td>0.5</td>\n      <td>0.167</td>\n      <td>0.833</td>\n      <td>0.000</td>\n      <td>0.4939</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>47</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>112.09</td>\n      <td>4.00</td>\n      <td>0.200</td>\n      <td>0.4</td>\n      <td>0.179</td>\n      <td>0.500</td>\n      <td>0.321</td>\n      <td>-0.2500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>89.75</td>\n      <td>6.61</td>\n      <td>-0.625</td>\n      <td>1.0</td>\n      <td>0.000</td>\n      <td>0.759</td>\n      <td>0.241</td>\n      <td>-0.6597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2009-04-06 22:20:00</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n      <td>0</td>\n      <td>22:20:00</td>\n      <td>2009-04-06</td>\n      <td>29</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>[]</td>\n      <td>117.16</td>\n      <td>2.00</td>\n      <td>0.200</td>\n      <td>0.4</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:50:56.383498333Z",
     "start_time": "2024-03-26T12:50:56.373083475Z"
    }
   },
   "id": "56d6cdb1d504c9fa",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.to_csv(\"./Data/tweets_features.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:50:59.398905873Z",
     "start_time": "2024-03-26T12:50:56.373734216Z"
    }
   },
   "id": "6426ad2cec3bb85e",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Target                Date           User  \\\n0       0 2009-04-06 22:19:49  scotthamilton   \n1       0 2009-04-06 22:19:53       mattycus   \n2       0 2009-04-06 22:19:57        ElleCTF   \n3       0 2009-04-06 22:19:57         Karoli   \n4       0 2009-04-06 22:20:00       joy_wolf   \n\n                                                Text  Weekday      Time  \\\n0  is upset that he can't update his Facebook by ...        0  22:19:49   \n1  @Kenichan I dived many times for the ball. Man...        0  22:19:53   \n2    my whole body feels itchy and like its on fire         0  22:19:57   \n3  @nationwideclass no, it's not behaving at all....        0  22:19:57   \n4                      @Kwesidei not the whole crew         0  22:20:00   \n\n    Full_date  Length  Hashtags  HasHashtags  ...     FRE   GFI  Polarity_TB  \\\n0  2009-04-06     111         0        False  ...   86.20  4.20        0.000   \n1  2009-04-06      89         0        False  ...  104.64  3.60        0.500   \n2  2009-04-06      47         0        False  ...  112.09  4.00        0.200   \n3  2009-04-06     111         0        False  ...   89.75  6.61       -0.625   \n4  2009-04-06      29         0        False  ...  117.16  2.00        0.200   \n\n   Subjectivity_TB Positive_VADER  Neutral_VADER  Negative_VADER  \\\n0              0.0          0.000          0.697           0.303   \n1              0.5          0.167          0.833           0.000   \n2              0.4          0.179          0.500           0.321   \n3              1.0          0.000          0.759           0.241   \n4              0.4          0.000          1.000           0.000   \n\n   Compound_VADER  Hour  skewed_hour_dist  \n0         -0.7500    22              0.75  \n1          0.4939    22              0.75  \n2         -0.2500    22              0.75  \n3         -0.6597    22              0.75  \n4          0.0000    22              0.75  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Date</th>\n      <th>User</th>\n      <th>Text</th>\n      <th>Weekday</th>\n      <th>Time</th>\n      <th>Full_date</th>\n      <th>Length</th>\n      <th>Hashtags</th>\n      <th>HasHashtags</th>\n      <th>...</th>\n      <th>FRE</th>\n      <th>GFI</th>\n      <th>Polarity_TB</th>\n      <th>Subjectivity_TB</th>\n      <th>Positive_VADER</th>\n      <th>Neutral_VADER</th>\n      <th>Negative_VADER</th>\n      <th>Compound_VADER</th>\n      <th>Hour</th>\n      <th>skewed_hour_dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:49</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>0</td>\n      <td>22:19:49</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>86.20</td>\n      <td>4.20</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.697</td>\n      <td>0.303</td>\n      <td>-0.7500</td>\n      <td>22</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:53</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>0</td>\n      <td>22:19:53</td>\n      <td>2009-04-06</td>\n      <td>89</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>104.64</td>\n      <td>3.60</td>\n      <td>0.500</td>\n      <td>0.5</td>\n      <td>0.167</td>\n      <td>0.833</td>\n      <td>0.000</td>\n      <td>0.4939</td>\n      <td>22</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>47</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>112.09</td>\n      <td>4.00</td>\n      <td>0.200</td>\n      <td>0.4</td>\n      <td>0.179</td>\n      <td>0.500</td>\n      <td>0.321</td>\n      <td>-0.2500</td>\n      <td>22</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>89.75</td>\n      <td>6.61</td>\n      <td>-0.625</td>\n      <td>1.0</td>\n      <td>0.000</td>\n      <td>0.759</td>\n      <td>0.241</td>\n      <td>-0.6597</td>\n      <td>22</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2009-04-06 22:20:00</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n      <td>0</td>\n      <td>22:20:00</td>\n      <td>2009-04-06</td>\n      <td>29</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>117.16</td>\n      <td>2.00</td>\n      <td>0.200</td>\n      <td>0.4</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>22</td>\n      <td>0.75</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'] = df['Date'].dt.hour\n",
    "df['skewed_hour_dist'] = df['Hour'].apply(lambda x: (16 - x) / 16 if x < 16 else (x - 16) / 8)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:50:59.472916756Z",
     "start_time": "2024-03-26T12:50:59.401558590Z"
    }
   },
   "id": "10530dea64cab04b",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Target                Date           User  \\\n0       0 2009-04-06 22:19:49  scotthamilton   \n1       0 2009-04-06 22:19:53       mattycus   \n2       0 2009-04-06 22:19:57        ElleCTF   \n3       0 2009-04-06 22:19:57         Karoli   \n4       0 2009-04-06 22:20:00       joy_wolf   \n\n                                                Text  Weekday      Time  \\\n0  is upset that he can't update his Facebook by ...        0  22:19:49   \n1  @Kenichan I dived many times for the ball. Man...        0  22:19:53   \n2    my whole body feels itchy and like its on fire         0  22:19:57   \n3  @nationwideclass no, it's not behaving at all....        0  22:19:57   \n4                      @Kwesidei not the whole crew         0  22:20:00   \n\n    Full_date  Length  Hashtags  HasHashtags  ...   GFI  Polarity_TB  \\\n0  2009-04-06     111         0        False  ...  4.20        0.000   \n1  2009-04-06      89         0        False  ...  3.60        0.500   \n2  2009-04-06      47         0        False  ...  4.00        0.200   \n3  2009-04-06     111         0        False  ...  6.61       -0.625   \n4  2009-04-06      29         0        False  ...  2.00        0.200   \n\n   Subjectivity_TB  Positive_VADER Neutral_VADER  Negative_VADER  \\\n0              0.0           0.000         0.697           0.303   \n1              0.5           0.167         0.833           0.000   \n2              0.4           0.179         0.500           0.321   \n3              1.0           0.000         0.759           0.241   \n4              0.4           0.000         1.000           0.000   \n\n   Compound_VADER  Hour  skewed_hour_dist  skewed_week_dist  \n0         -0.7500    22              0.75               1.0  \n1          0.4939    22              0.75               1.0  \n2         -0.2500    22              0.75               1.0  \n3         -0.6597    22              0.75               1.0  \n4          0.0000    22              0.75               1.0  \n\n[5 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Date</th>\n      <th>User</th>\n      <th>Text</th>\n      <th>Weekday</th>\n      <th>Time</th>\n      <th>Full_date</th>\n      <th>Length</th>\n      <th>Hashtags</th>\n      <th>HasHashtags</th>\n      <th>...</th>\n      <th>GFI</th>\n      <th>Polarity_TB</th>\n      <th>Subjectivity_TB</th>\n      <th>Positive_VADER</th>\n      <th>Neutral_VADER</th>\n      <th>Negative_VADER</th>\n      <th>Compound_VADER</th>\n      <th>Hour</th>\n      <th>skewed_hour_dist</th>\n      <th>skewed_week_dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:49</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>0</td>\n      <td>22:19:49</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>4.20</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.697</td>\n      <td>0.303</td>\n      <td>-0.7500</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:53</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>0</td>\n      <td>22:19:53</td>\n      <td>2009-04-06</td>\n      <td>89</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>3.60</td>\n      <td>0.500</td>\n      <td>0.5</td>\n      <td>0.167</td>\n      <td>0.833</td>\n      <td>0.000</td>\n      <td>0.4939</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>47</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>4.00</td>\n      <td>0.200</td>\n      <td>0.4</td>\n      <td>0.179</td>\n      <td>0.500</td>\n      <td>0.321</td>\n      <td>-0.2500</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>6.61</td>\n      <td>-0.625</td>\n      <td>1.0</td>\n      <td>0.000</td>\n      <td>0.759</td>\n      <td>0.241</td>\n      <td>-0.6597</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2009-04-06 22:20:00</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n      <td>0</td>\n      <td>22:20:00</td>\n      <td>2009-04-06</td>\n      <td>29</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>2.00</td>\n      <td>0.200</td>\n      <td>0.4</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It is kind of forced but we can try doing similar thing with Weekday\n",
    "df['skewed_week_dist'] = df['Weekday'].apply(lambda x: (2 - x) / 2 if x < 2 else (x - 2) / 4)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:50:59.721505392Z",
     "start_time": "2024-03-26T12:50:59.475568340Z"
    }
   },
   "id": "31e5649b5b0afec0",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Target                Date           User  \\\n0       0 2009-04-06 22:19:49  scotthamilton   \n1       0 2009-04-06 22:19:53       mattycus   \n2       0 2009-04-06 22:19:57        ElleCTF   \n3       0 2009-04-06 22:19:57         Karoli   \n4       0 2009-04-06 22:20:00       joy_wolf   \n\n                                                Text  Weekday      Time  \\\n0  is upset that he can't update his Facebook by ...        0  22:19:49   \n1  @Kenichan I dived many times for the ball. Man...        0  22:19:53   \n2    my whole body feels itchy and like its on fire         0  22:19:57   \n3  @nationwideclass no, it's not behaving at all....        0  22:19:57   \n4                      @Kwesidei not the whole crew         0  22:20:00   \n\n    Full_date  Length  Hashtags  HasHashtags  ...  Polarity_TB  \\\n0  2009-04-06     111         0        False  ...        0.000   \n1  2009-04-06      89         0        False  ...        0.500   \n2  2009-04-06      47         0        False  ...        0.200   \n3  2009-04-06     111         0        False  ...       -0.625   \n4  2009-04-06      29         0        False  ...        0.200   \n\n   Subjectivity_TB  Positive_VADER  Neutral_VADER Negative_VADER  \\\n0              0.0           0.000          0.697          0.303   \n1              0.5           0.167          0.833          0.000   \n2              0.4           0.179          0.500          0.321   \n3              1.0           0.000          0.759          0.241   \n4              0.4           0.000          1.000          0.000   \n\n   Compound_VADER  Hour  skewed_hour_dist  skewed_week_dist  \\\n0         -0.7500    22              0.75               1.0   \n1          0.4939    22              0.75               1.0   \n2         -0.2500    22              0.75               1.0   \n3         -0.6597    22              0.75               1.0   \n4          0.0000    22              0.75               1.0   \n\n   is_after_certain_day  \n0                     0  \n1                     0  \n2                     0  \n3                     0  \n4                     0  \n\n[5 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Date</th>\n      <th>User</th>\n      <th>Text</th>\n      <th>Weekday</th>\n      <th>Time</th>\n      <th>Full_date</th>\n      <th>Length</th>\n      <th>Hashtags</th>\n      <th>HasHashtags</th>\n      <th>...</th>\n      <th>Polarity_TB</th>\n      <th>Subjectivity_TB</th>\n      <th>Positive_VADER</th>\n      <th>Neutral_VADER</th>\n      <th>Negative_VADER</th>\n      <th>Compound_VADER</th>\n      <th>Hour</th>\n      <th>skewed_hour_dist</th>\n      <th>skewed_week_dist</th>\n      <th>is_after_certain_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:49</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>0</td>\n      <td>22:19:49</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.697</td>\n      <td>0.303</td>\n      <td>-0.7500</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:53</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>0</td>\n      <td>22:19:53</td>\n      <td>2009-04-06</td>\n      <td>89</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.500</td>\n      <td>0.5</td>\n      <td>0.167</td>\n      <td>0.833</td>\n      <td>0.000</td>\n      <td>0.4939</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>47</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.200</td>\n      <td>0.4</td>\n      <td>0.179</td>\n      <td>0.500</td>\n      <td>0.321</td>\n      <td>-0.2500</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>-0.625</td>\n      <td>1.0</td>\n      <td>0.000</td>\n      <td>0.759</td>\n      <td>0.241</td>\n      <td>-0.6597</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2009-04-06 22:20:00</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n      <td>0</td>\n      <td>22:20:00</td>\n      <td>2009-04-06</td>\n      <td>29</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.200</td>\n      <td>0.4</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have seen that after certain date (2009-05-29 07:33:45) sentiment of all tweets is negative. Of course it is a feature\n",
    "#strictly specific to our data and according to common sense shouldn't be used in the model if we would like to predict the sentiment\n",
    "#of any text. However if testing is going to be done on our set alone it is a meaningful piece of information.\n",
    "y = df[df['Target'] == 1]['Full_date'].max()\n",
    "df['is_after_certain_day'] = df['Full_date'].apply(lambda x: 0 if x <= y else 1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:50:59.736792190Z",
     "start_time": "2024-03-26T12:50:59.551835125Z"
    }
   },
   "id": "33d36572b711730b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Target                Date           User  \\\n0       0 2009-04-06 22:19:49  scotthamilton   \n1       0 2009-04-06 22:19:53       mattycus   \n2       0 2009-04-06 22:19:57        ElleCTF   \n3       0 2009-04-06 22:19:57         Karoli   \n4       0 2009-04-06 22:20:00       joy_wolf   \n\n                                                Text  Weekday      Time  \\\n0  is upset that he can't update his Facebook by ...        0  22:19:49   \n1  @Kenichan I dived many times for the ball. Man...        0  22:19:53   \n2    my whole body feels itchy and like its on fire         0  22:19:57   \n3  @nationwideclass no, it's not behaving at all....        0  22:19:57   \n4                      @Kwesidei not the whole crew         0  22:20:00   \n\n    Full_date  Length  Hashtags  HasHashtags  ...  Positive_VADER  \\\n0  2009-04-06     111         0        False  ...           0.000   \n1  2009-04-06      89         0        False  ...           0.167   \n2  2009-04-06      47         0        False  ...           0.179   \n3  2009-04-06     111         0        False  ...           0.000   \n4  2009-04-06      29         0        False  ...           0.000   \n\n   Neutral_VADER  Negative_VADER  Compound_VADER Hour  skewed_hour_dist  \\\n0          0.697           0.303         -0.7500   22              0.75   \n1          0.833           0.000          0.4939   22              0.75   \n2          0.500           0.321         -0.2500   22              0.75   \n3          0.759           0.241         -0.6597   22              0.75   \n4          1.000           0.000          0.0000   22              0.75   \n\n   skewed_week_dist  is_after_certain_day  has_mentions  has_exclamation_marks  \n0               1.0                     0             0                      0  \n1               1.0                     0             1                      0  \n2               1.0                     0             0                      0  \n3               1.0                     0             1                      0  \n4               1.0                     0             1                      0  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Date</th>\n      <th>User</th>\n      <th>Text</th>\n      <th>Weekday</th>\n      <th>Time</th>\n      <th>Full_date</th>\n      <th>Length</th>\n      <th>Hashtags</th>\n      <th>HasHashtags</th>\n      <th>...</th>\n      <th>Positive_VADER</th>\n      <th>Neutral_VADER</th>\n      <th>Negative_VADER</th>\n      <th>Compound_VADER</th>\n      <th>Hour</th>\n      <th>skewed_hour_dist</th>\n      <th>skewed_week_dist</th>\n      <th>is_after_certain_day</th>\n      <th>has_mentions</th>\n      <th>has_exclamation_marks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:49</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>0</td>\n      <td>22:19:49</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.697</td>\n      <td>0.303</td>\n      <td>-0.7500</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:53</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>0</td>\n      <td>22:19:53</td>\n      <td>2009-04-06</td>\n      <td>89</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.167</td>\n      <td>0.833</td>\n      <td>0.000</td>\n      <td>0.4939</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>47</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.179</td>\n      <td>0.500</td>\n      <td>0.321</td>\n      <td>-0.2500</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.759</td>\n      <td>0.241</td>\n      <td>-0.6597</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2009-04-06 22:20:00</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n      <td>0</td>\n      <td>22:20:00</td>\n      <td>2009-04-06</td>\n      <td>29</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>22</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thaks to one of correlation matrices from EDA (or to having at least 1 brain cell) we know that the number of hashtags, mentions or\n",
    "#exclamation marks is highly correlated with its binary counterpart quantifier. From the same analysis we see that their correlation with \n",
    "# target is marginal however mentions and exclamation marks seem to have more to say than hashtags, that is why we \n",
    "#will leave out hashtags but not the other two.\n",
    "def has_men(text):\n",
    "    for c in text:\n",
    "        if c == '@':\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def has_exc(text):\n",
    "    for c in text:\n",
    "        if c == '!':\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "\n",
    "df['has_mentions'] = df['Text'].apply(has_men)\n",
    "df['has_exclamation_marks'] = df['Text'].apply(has_exc)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:51:00.099590040Z",
     "start_time": "2024-03-26T12:50:59.674470987Z"
    }
   },
   "id": "e6ff78cfadf5cdb8",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   Target                Date           User  \\\n0     0.0 2009-04-06 22:19:49  scotthamilton   \n1     0.0 2009-04-06 22:19:53       mattycus   \n2     0.0 2009-04-06 22:19:57        ElleCTF   \n3     0.0 2009-04-06 22:19:57         Karoli   \n4     0.0 2009-04-06 22:20:00       joy_wolf   \n\n                                                Text  Weekday      Time  \\\n0  is upset that he can't update his Facebook by ...      0.0  22:19:49   \n1  @Kenichan I dived many times for the ball. Man...      0.0  22:19:53   \n2    my whole body feels itchy and like its on fire       0.0  22:19:57   \n3  @nationwideclass no, it's not behaving at all....      0.0  22:19:57   \n4                      @Kwesidei not the whole crew       0.0  22:20:00   \n\n    Full_date  Length  Hashtags HasHashtags  ...  watching  way  week weekend  \\\n0  2009-04-06   111.0       0.0       False  ...       0.0  0.0   0.0     0.0   \n1  2009-04-06    89.0       0.0       False  ...       0.0  0.0   0.0     0.0   \n2  2009-04-06    47.0       0.0       False  ...       0.0  0.0   0.0     0.0   \n3  2009-04-06   111.0       0.0       False  ...       0.0  0.0   0.0     0.0   \n4  2009-04-06    29.0       0.0       False  ...       0.0  0.0   0.0     0.0   \n\n  wish  work  working  yay  yeah  yes  \n0  0.0   0.0      0.0  0.0   0.0  0.0  \n1  0.0   0.0      0.0  0.0   0.0  0.0  \n2  0.0   0.0      0.0  0.0   0.0  0.0  \n3  0.0   0.0      0.0  0.0   0.0  0.0  \n4  0.0   0.0      0.0  0.0   0.0  0.0  \n\n[5 rows x 129 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Date</th>\n      <th>User</th>\n      <th>Text</th>\n      <th>Weekday</th>\n      <th>Time</th>\n      <th>Full_date</th>\n      <th>Length</th>\n      <th>Hashtags</th>\n      <th>HasHashtags</th>\n      <th>...</th>\n      <th>watching</th>\n      <th>way</th>\n      <th>week</th>\n      <th>weekend</th>\n      <th>wish</th>\n      <th>work</th>\n      <th>working</th>\n      <th>yay</th>\n      <th>yeah</th>\n      <th>yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>2009-04-06 22:19:49</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>0.0</td>\n      <td>22:19:49</td>\n      <td>2009-04-06</td>\n      <td>111.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>2009-04-06 22:19:53</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>0.0</td>\n      <td>22:19:53</td>\n      <td>2009-04-06</td>\n      <td>89.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>0.0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>47.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>0.0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>111.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>2009-04-06 22:20:00</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n      <td>0.0</td>\n      <td>22:20:00</td>\n      <td>2009-04-06</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 129 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And now for the main course tf-idf, we will set a limit o a 100 words so as not to everything too high in computation cost.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_data = df['Text'].tolist()\n",
    "\n",
    "#We shall also remove certain english stop words because they are very frequent but do not carry much sentiment.\n",
    "vectoriser = TfidfVectorizer(max_features=100, lowercase=True, stop_words='english')\n",
    "tfidf_matrix = vectoriser.fit_transform(text_data)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectoriser.get_feature_names_out())\n",
    "df_tfidf = pd.concat([df, tfidf_df], axis=1)\n",
    "df_tfidf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:51:03.259262127Z",
     "start_time": "2024-03-26T12:51:00.125111347Z"
    }
   },
   "id": "cf2e7bca9e0a34ff",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "custom_stopwords = set(stopwords.words('english')) - {'no', 'not', 'nor', \"isn't\", \"wasn't\", \"aren't\", \"don't\",\n",
    "                                                      \"didn't\", \"cannot\", \"couldn't\", \"shouldn't\"}\n",
    "\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "    tweet = re.sub(r'\\@\\w+|\\#', '', tweet)\n",
    "    tweet = re.sub(r'\\W', ' ', tweet)\n",
    "    tweet = emoji.demojize(tweet, delimiters=(\"\", \" \"))\n",
    "    tokens = word_tokenize(tweet)\n",
    "    tokens = [word for word in tokens if word not in custom_stopwords]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "df['ProcessedText'] = df['Text'].apply(preprocess_tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:51:45.610515639Z",
     "start_time": "2024-03-26T12:51:03.260270118Z"
    }
   },
   "id": "b381e6b08b08a36c",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "texts = df['ProcessedText'].tolist()\n",
    "\n",
    "tokenized_texts = [text.split() for text in texts]\n",
    "\n",
    "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "\n",
    "def tweet_vector(tweet, model):\n",
    "    words = tweet.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    else:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "\n",
    "\n",
    "df[\"w2v\"] = np.array([np.mean(tweet_vector(tweet, word2vec_model)) for tweet in texts])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:52:01.339442680Z",
     "start_time": "2024-03-26T12:51:45.652356591Z"
    }
   },
   "id": "275841ba2899eed2",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "def get_tiktoken_embedding(text):\n",
    "    embeddings = encoding.encode(text)\n",
    "    if len(embeddings) == 0:\n",
    "        return 0, 0, 0\n",
    "    return np.mean(embeddings, axis=0), np.max(embeddings, axis=0), np.min(embeddings, axis=0)\n",
    "\n",
    "\n",
    "df[[\"tt_embedding_mean\", \"tt_embedding_max\", \"tt_embedding_min\"]] = np.array(\n",
    "    [get_tiktoken_embedding(text) for text in texts])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:52:14.490414249Z",
     "start_time": "2024-03-26T12:52:01.341551135Z"
    }
   },
   "id": "7258b14eb34c15ac",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def get_weighted_embedding(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    embeddings = []\n",
    "    weights = []\n",
    "    for word, tag in tagged_tokens:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        embedding = encoding.encode(word)\n",
    "        weight = 1.5 if tag.startswith('JJ') else 1.0\n",
    "        embeddings.append(np.average(embedding) * weight)\n",
    "\n",
    "    if len(embeddings) == 0:\n",
    "        return 0\n",
    "    weighted_embeddings = np.average(embeddings, axis=0)\n",
    "    return weighted_embeddings\n",
    "\n",
    "\n",
    "df[\"tt_embedding_weighted\"] = np.array([get_weighted_embedding(text) for text in texts])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:54:42.079327717Z",
     "start_time": "2024-03-26T12:52:14.493095159Z"
    }
   },
   "id": "b99734c6a9b13c30",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "texts = df['ProcessedText']\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "def top_n_words(row, feature_names, n=3):\n",
    "    top_n_idx = np.argsort(row)[-n:]\n",
    "    top_n_values = [feature_names[i] for i in top_n_idx]\n",
    "    return top_n_values\n",
    "df[[\"Word_1\", \"Word_2\", \"Word_3\"]] = [top_n_words(row, feature_names) for row in tfidf_array]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:54:49.488908378Z",
     "start_time": "2024-03-26T12:54:42.136192243Z"
    }
   },
   "id": "399a3055adf41b59",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_tiktoken_embedding(text):\n",
    "    embeddings = encoding.encode(text)\n",
    "    if len(embeddings) == 0:\n",
    "        return 0, 0, 0\n",
    "    return np.mean(embeddings, axis=0), np.max(embeddings, axis=0), np.min(embeddings, axis=0)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    words = df[f\"Word_{i}\"]\n",
    "    df[[f\"Word_{i}_embedding_mean\", f\"Word_{i}_embedding_max\", f\"Word_{i}_embedding_min\"]] = np.array(\n",
    "        [get_tiktoken_embedding(word) for word in words])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:55:08.821302815Z",
     "start_time": "2024-03-26T12:54:49.490667799Z"
    }
   },
   "id": "cd33a5bfd6585e5b",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "         Target                Date           User  \\\n0             0 2009-04-06 22:19:49  scotthamilton   \n1             0 2009-04-06 22:19:53       mattycus   \n2             0 2009-04-06 22:19:57        ElleCTF   \n3             0 2009-04-06 22:19:57         Karoli   \n4             0 2009-04-06 22:20:00       joy_wolf   \n...         ...                 ...            ...   \n1033282       1 2009-05-27 07:27:38       LizAnjos   \n1033283       1 2009-05-27 07:27:38  TiernanDouieb   \n1033284       1 2009-05-27 07:27:38    ExpertDater   \n1033285       1 2009-05-27 07:27:38         bpende   \n1033286       1 2009-05-27 07:27:38   svenringling   \n\n                                                      Text  Weekday      Time  \\\n0        is upset that he can't update his Facebook by ...        0  22:19:49   \n1        @Kenichan I dived many times for the ball. Man...        0  22:19:53   \n2          my whole body feels itchy and like its on fire         0  22:19:57   \n3        @nationwideclass no, it's not behaving at all....        0  22:19:57   \n4                            @Kwesidei not the whole crew         0  22:20:00   \n...                                                    ...      ...       ...   \n1033282  @NintendoRed sometimes, you just have to let go!         2  07:27:38   \n1033283  @misswiz ah. Perhaps point her in the directio...        2  07:27:38   \n1033284  @SingleInThe604 Nice to meet you u too! Im gla...        2  07:27:38   \n1033285  @ChrisCavs : I love you, man... you making me ...        2  07:27:38   \n1033286  Recently published book on HR-IT keeps bringin...        2  07:27:38   \n\n          Full_date  Length  Hashtags  HasHashtags  ...     Word_3  \\\n0        2009-04-06     111         0        False  ...     result   \n1        2009-04-06      89         0        False  ...         50   \n2        2009-04-06      47         0        False  ...       fire   \n3        2009-04-06     111         0        False  ...        mad   \n4        2009-04-06      29         0        False  ...      whole   \n...             ...     ...       ...          ...  ...        ...   \n1033282  2009-05-27      49         0        False  ...  sometimes   \n1033283  2009-05-27      64         0        False  ...      point   \n1033284  2009-05-27      70         0        False  ...    article   \n1033285  2009-05-27      71         0        False  ...     making   \n1033286  2009-05-27     118         0        False  ...         hr   \n\n         Word_1_embedding_mean  Word_1_embedding_max  Word_1_embedding_min  \\\n0                      21617.0               21617.0               21617.0   \n1                       6766.0                6766.0                6766.0   \n2                      67733.0               67733.0               67733.0   \n3                       2201.0                2201.0                2201.0   \n4                        271.5                 455.0                  88.0   \n...                        ...                   ...                   ...   \n1033282                 3427.0                3427.0                3427.0   \n1033283                  606.0                 606.0                 606.0   \n1033284                64510.0               64510.0               64510.0   \n1033285                58234.0               58234.0               58234.0   \n1033286                10816.0               10816.0               10816.0   \n\n        Word_2_embedding_mean  Word_2_embedding_max  Word_2_embedding_min  \\\n0                  603.000000                 751.0                 455.0   \n1                 4047.000000                4047.0                4047.0   \n2                 2664.000000                2664.0                2664.0   \n3                 4151.000000                4151.0                4151.0   \n4                 1962.000000                1962.0                1962.0   \n...                       ...                   ...                   ...   \n1033282           1169.000000                1169.0                1169.0   \n1033283           1494.000000                1494.0                1494.0   \n1033284           1591.333333                4215.0                 268.0   \n1033285           1543.000000                1543.0                1543.0   \n1033286           2239.000000                2239.0                2239.0   \n\n         Word_3_embedding_mean  Word_3_embedding_max  Word_3_embedding_min  \n0                       1407.0                1407.0                1407.0  \n1                       1135.0                1135.0                1135.0  \n2                      11029.0               11029.0               11029.0  \n3                      20920.0               20920.0               20920.0  \n4                      67733.0               67733.0               67733.0  \n...                        ...                   ...                   ...  \n1033282                57753.0               57753.0               57753.0  \n1033283                 2837.0                2837.0                2837.0  \n1033284                 7203.0                7203.0                7203.0  \n1033285                28936.0               28936.0               28936.0  \n1033286                 4171.0                4171.0                4171.0  \n\n[388400 rows x 47 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>Date</th>\n      <th>User</th>\n      <th>Text</th>\n      <th>Weekday</th>\n      <th>Time</th>\n      <th>Full_date</th>\n      <th>Length</th>\n      <th>Hashtags</th>\n      <th>HasHashtags</th>\n      <th>...</th>\n      <th>Word_3</th>\n      <th>Word_1_embedding_mean</th>\n      <th>Word_1_embedding_max</th>\n      <th>Word_1_embedding_min</th>\n      <th>Word_2_embedding_mean</th>\n      <th>Word_2_embedding_max</th>\n      <th>Word_2_embedding_min</th>\n      <th>Word_3_embedding_mean</th>\n      <th>Word_3_embedding_max</th>\n      <th>Word_3_embedding_min</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:49</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>0</td>\n      <td>22:19:49</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>result</td>\n      <td>21617.0</td>\n      <td>21617.0</td>\n      <td>21617.0</td>\n      <td>603.000000</td>\n      <td>751.0</td>\n      <td>455.0</td>\n      <td>1407.0</td>\n      <td>1407.0</td>\n      <td>1407.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:53</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>0</td>\n      <td>22:19:53</td>\n      <td>2009-04-06</td>\n      <td>89</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>50</td>\n      <td>6766.0</td>\n      <td>6766.0</td>\n      <td>6766.0</td>\n      <td>4047.000000</td>\n      <td>4047.0</td>\n      <td>4047.0</td>\n      <td>1135.0</td>\n      <td>1135.0</td>\n      <td>1135.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>47</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>fire</td>\n      <td>67733.0</td>\n      <td>67733.0</td>\n      <td>67733.0</td>\n      <td>2664.000000</td>\n      <td>2664.0</td>\n      <td>2664.0</td>\n      <td>11029.0</td>\n      <td>11029.0</td>\n      <td>11029.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2009-04-06 22:19:57</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>0</td>\n      <td>22:19:57</td>\n      <td>2009-04-06</td>\n      <td>111</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>mad</td>\n      <td>2201.0</td>\n      <td>2201.0</td>\n      <td>2201.0</td>\n      <td>4151.000000</td>\n      <td>4151.0</td>\n      <td>4151.0</td>\n      <td>20920.0</td>\n      <td>20920.0</td>\n      <td>20920.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2009-04-06 22:20:00</td>\n      <td>joy_wolf</td>\n      <td>@Kwesidei not the whole crew</td>\n      <td>0</td>\n      <td>22:20:00</td>\n      <td>2009-04-06</td>\n      <td>29</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>whole</td>\n      <td>271.5</td>\n      <td>455.0</td>\n      <td>88.0</td>\n      <td>1962.000000</td>\n      <td>1962.0</td>\n      <td>1962.0</td>\n      <td>67733.0</td>\n      <td>67733.0</td>\n      <td>67733.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1033282</th>\n      <td>1</td>\n      <td>2009-05-27 07:27:38</td>\n      <td>LizAnjos</td>\n      <td>@NintendoRed sometimes, you just have to let go!</td>\n      <td>2</td>\n      <td>07:27:38</td>\n      <td>2009-05-27</td>\n      <td>49</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>sometimes</td>\n      <td>3427.0</td>\n      <td>3427.0</td>\n      <td>3427.0</td>\n      <td>1169.000000</td>\n      <td>1169.0</td>\n      <td>1169.0</td>\n      <td>57753.0</td>\n      <td>57753.0</td>\n      <td>57753.0</td>\n    </tr>\n    <tr>\n      <th>1033283</th>\n      <td>1</td>\n      <td>2009-05-27 07:27:38</td>\n      <td>TiernanDouieb</td>\n      <td>@misswiz ah. Perhaps point her in the directio...</td>\n      <td>2</td>\n      <td>07:27:38</td>\n      <td>2009-05-27</td>\n      <td>64</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>point</td>\n      <td>606.0</td>\n      <td>606.0</td>\n      <td>606.0</td>\n      <td>1494.000000</td>\n      <td>1494.0</td>\n      <td>1494.0</td>\n      <td>2837.0</td>\n      <td>2837.0</td>\n      <td>2837.0</td>\n    </tr>\n    <tr>\n      <th>1033284</th>\n      <td>1</td>\n      <td>2009-05-27 07:27:38</td>\n      <td>ExpertDater</td>\n      <td>@SingleInThe604 Nice to meet you u too! Im gla...</td>\n      <td>2</td>\n      <td>07:27:38</td>\n      <td>2009-05-27</td>\n      <td>70</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>article</td>\n      <td>64510.0</td>\n      <td>64510.0</td>\n      <td>64510.0</td>\n      <td>1591.333333</td>\n      <td>4215.0</td>\n      <td>268.0</td>\n      <td>7203.0</td>\n      <td>7203.0</td>\n      <td>7203.0</td>\n    </tr>\n    <tr>\n      <th>1033285</th>\n      <td>1</td>\n      <td>2009-05-27 07:27:38</td>\n      <td>bpende</td>\n      <td>@ChrisCavs : I love you, man... you making me ...</td>\n      <td>2</td>\n      <td>07:27:38</td>\n      <td>2009-05-27</td>\n      <td>71</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>making</td>\n      <td>58234.0</td>\n      <td>58234.0</td>\n      <td>58234.0</td>\n      <td>1543.000000</td>\n      <td>1543.0</td>\n      <td>1543.0</td>\n      <td>28936.0</td>\n      <td>28936.0</td>\n      <td>28936.0</td>\n    </tr>\n    <tr>\n      <th>1033286</th>\n      <td>1</td>\n      <td>2009-05-27 07:27:38</td>\n      <td>svenringling</td>\n      <td>Recently published book on HR-IT keeps bringin...</td>\n      <td>2</td>\n      <td>07:27:38</td>\n      <td>2009-05-27</td>\n      <td>118</td>\n      <td>0</td>\n      <td>False</td>\n      <td>...</td>\n      <td>hr</td>\n      <td>10816.0</td>\n      <td>10816.0</td>\n      <td>10816.0</td>\n      <td>2239.000000</td>\n      <td>2239.0</td>\n      <td>2239.0</td>\n      <td>4171.0</td>\n      <td>4171.0</td>\n      <td>4171.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>388400 rows × 47 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:55:09.048080024Z",
     "start_time": "2024-03-26T12:55:08.833563145Z"
    }
   },
   "id": "d8f04e4bfacd71ab",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_topics = 10\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=0)\n",
    "lda.fit(tfidf_matrix)\n",
    "topic_distribution = lda.transform(tfidf_matrix)\n",
    "dominant_topic = np.argmax(topic_distribution, axis=1)\n",
    "df['DominantTopic'] = dominant_topic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T12:59:47.676246893Z",
     "start_time": "2024-03-26T12:55:09.039443863Z"
    }
   },
   "id": "c10493f9600b4989",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.to_csv(\"./Data/tweets_features.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T13:01:31.331932273Z",
     "start_time": "2024-03-26T13:01:25.221440902Z"
    }
   },
   "id": "25f5efe8d7c026bc",
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
