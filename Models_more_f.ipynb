{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:51:39.518279655Z",
     "start_time": "2024-04-21T17:51:39.027464988Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d04b62db515eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:51:51.850865693Z",
     "start_time": "2024-04-21T17:51:39.518560662Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/tweets_features.csv\", encoding='latin')\n",
    "df.drop(['is_after_certain_day', 'Date', 'User', 'Text', 'Time', 'Full_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ed935cc58ad477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:51:51.865272371Z",
     "start_time": "2024-04-21T17:51:51.854379543Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Length</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>HasHashtags</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>HasMentions</th>\n",
       "      <th>ExclamationMarks</th>\n",
       "      <th>HasExclamationMarks</th>\n",
       "      <th>Emoticons</th>\n",
       "      <th>...</th>\n",
       "      <th>w2v_90</th>\n",
       "      <th>w2v_91</th>\n",
       "      <th>w2v_92</th>\n",
       "      <th>w2v_93</th>\n",
       "      <th>w2v_94</th>\n",
       "      <th>w2v_95</th>\n",
       "      <th>w2v_96</th>\n",
       "      <th>w2v_97</th>\n",
       "      <th>w2v_98</th>\n",
       "      <th>w2v_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576463</td>\n",
       "      <td>0.272287</td>\n",
       "      <td>-0.270659</td>\n",
       "      <td>0.398829</td>\n",
       "      <td>0.806970</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.261823</td>\n",
       "      <td>-0.655965</td>\n",
       "      <td>0.179224</td>\n",
       "      <td>-0.132590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400095</td>\n",
       "      <td>0.262307</td>\n",
       "      <td>0.052329</td>\n",
       "      <td>0.443299</td>\n",
       "      <td>0.895985</td>\n",
       "      <td>0.565586</td>\n",
       "      <td>0.221301</td>\n",
       "      <td>-0.797784</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>0.002357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460558</td>\n",
       "      <td>0.378846</td>\n",
       "      <td>-0.171764</td>\n",
       "      <td>0.227248</td>\n",
       "      <td>0.303033</td>\n",
       "      <td>0.620672</td>\n",
       "      <td>0.146584</td>\n",
       "      <td>-0.615910</td>\n",
       "      <td>0.112132</td>\n",
       "      <td>-0.088989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535103</td>\n",
       "      <td>0.073591</td>\n",
       "      <td>-0.307203</td>\n",
       "      <td>0.651506</td>\n",
       "      <td>0.309582</td>\n",
       "      <td>0.018715</td>\n",
       "      <td>-0.205674</td>\n",
       "      <td>-0.595330</td>\n",
       "      <td>0.333111</td>\n",
       "      <td>0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484578</td>\n",
       "      <td>0.324513</td>\n",
       "      <td>-0.259205</td>\n",
       "      <td>0.183831</td>\n",
       "      <td>0.745856</td>\n",
       "      <td>0.448028</td>\n",
       "      <td>0.359533</td>\n",
       "      <td>-0.555516</td>\n",
       "      <td>-0.176974</td>\n",
       "      <td>-0.091381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target  Weekday  Length  Hashtags  HasHashtags  Mentions  HasMentions  \\\n",
       "0       0        4     111         0        False         0        False   \n",
       "1       0        2     131         0        False         0        False   \n",
       "2       0        1      41         0        False         1         True   \n",
       "3       0        6      72         0        False         0        False   \n",
       "4       1        0      57         0        False         1         True   \n",
       "\n",
       "   ExclamationMarks  HasExclamationMarks Emoticons  ...    w2v_90    w2v_91  \\\n",
       "0                 0                False        []  ...  0.576463  0.272287   \n",
       "1                 0                False        []  ...  0.400095  0.262307   \n",
       "2                 2                 True        []  ...  0.460558  0.378846   \n",
       "3                 0                False        []  ...  0.535103  0.073591   \n",
       "4                 0                False        []  ...  0.484578  0.324513   \n",
       "\n",
       "     w2v_92    w2v_93    w2v_94    w2v_95    w2v_96    w2v_97    w2v_98  \\\n",
       "0 -0.270659  0.398829  0.806970  0.539171  0.261823 -0.655965  0.179224   \n",
       "1  0.052329  0.443299  0.895985  0.565586  0.221301 -0.797784  0.020691   \n",
       "2 -0.171764  0.227248  0.303033  0.620672  0.146584 -0.615910  0.112132   \n",
       "3 -0.307203  0.651506  0.309582  0.018715 -0.205674 -0.595330  0.333111   \n",
       "4 -0.259205  0.183831  0.745856  0.448028  0.359533 -0.555516 -0.176974   \n",
       "\n",
       "     w2v_99  \n",
       "0 -0.132590  \n",
       "1  0.002357  \n",
       "2 -0.088989  \n",
       "3  0.001450  \n",
       "4 -0.091381  \n",
       "\n",
       "[5 rows x 541 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e101762aa0376",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:51:51.886744510Z",
     "start_time": "2024-04-21T17:51:51.867970481Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "selected_columns = ['Negative_VADER', 'skewed_hour_dist', 'Weekday', 'Compound_VADER',\n",
    "                    'skewed_week_dist', 'w2v_11', 'Mentions', 'Polarity_TB', 'w2v_27',\n",
    "                    'w2v_53', 'Hour', 'w2v_44', 'w2v_84', 'embedding_16', 'w2v_47',\n",
    "                    'Positive_VADER', 'embedding_239', 'Length', 'embedding_284',\n",
    "                    'embedding_263', 'embedding_153', 'embedding_301', 'w2v_76',\n",
    "                    'embedding_220', 'embedding_366', 'w2v_29', 'w2v_61', 'embedding_28',\n",
    "                    'embedding_168', 'embedding_272', 'embedding_253', 'embedding_85',\n",
    "                    'embedding_285', 'w2v_12', 'w2v_31', 'embedding_120', 'embedding_254',\n",
    "                    'w2v_73', 'w2v_67', 'embedding_174', 'embedding_225', 'embedding_297',\n",
    "                    'embedding_68', 'embedding_211', 'embedding_178']\n",
    "\n",
    "df = df[selected_columns + ['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559afc3eb5393f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:51:51.904699613Z",
     "start_time": "2024-04-21T17:51:51.882346382Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_classifiers(X, y, classifiers, param_distributions, cv_folds=5, n_iter=10):\n",
    "    results = {}\n",
    "    best_models = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), (name.lower().replace(\" \", \"\"), clf)])\n",
    "        search = TuneSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=param_distributions.get(name, {}),\n",
    "            n_trials=n_iter,\n",
    "            cv=cv_folds,\n",
    "            scoring='accuracy',\n",
    "            search_optimization=\"random\",\n",
    "            verbose=1,\n",
    "            random_state=42\n",
    "        )\n",
    "        search.fit(X, y)\n",
    "        best_models[name] = search.best_estimator_\n",
    "        results[name] = search.cv_results_\n",
    "        print(f\"{name} Best Accuracy: {search.best_score_:.2f}\")\n",
    "        print(f\"Best Parameters: {search.best_params_}\")\n",
    "\n",
    "    sorted_models = sorted(best_models.items(), key=lambda x: x[1].score(X, y), reverse=True)[:3]\n",
    "    return results, sorted_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a60216344cd3be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:51:52.414204141Z",
     "start_time": "2024-04-21T17:51:51.887404338Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = df.drop(['Target'], axis=1)\n",
    "y = df['Target']\n",
    "X = X.select_dtypes(include=['number'])\n",
    "\n",
    "\n",
    "def objective(trial, classifier_name, model, param_grid):\n",
    "    params = {}\n",
    "    for key, values in param_grid.items():\n",
    "        if isinstance(values, list):\n",
    "            params[key] = trial.suggest_categorical(key, values)\n",
    "        elif isinstance(values, tuple) and len(values) == 3 and values[2] == 'log':\n",
    "            params[key] = trial.suggest_float(key, values[0], values[1], log=True)\n",
    "        elif isinstance(values, tuple):\n",
    "            params[key] = trial.suggest_float(key, values[0], values[1])\n",
    "\n",
    "    clf = model(**params)\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', clf)])\n",
    "    score = cross_val_score(pipeline, X, y, n_jobs=-1, cv=5).mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {'C': (1e-4, 1e4, 'log')},\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    'k-Nearest Neighbors': {'n_neighbors': list(range(1, 21))},\n",
    "    'Decision Tree': {'max_depth': list(range(1, 21))},\n",
    "    'Naive Bayes': {}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad8cfc9db6fc8165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T16:14:30.300100615Z",
     "start_time": "2024-04-21T16:08:17.582938823Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 18:08:17,582] A new study created in memory with name: no-name-8c54aabf-a7e6-4ced-b8a1-730499cd18a3\n",
      "[I 2024-04-21 18:08:19,565] Trial 0 finished with value: 0.77973 and parameters: {'C': 22.77468947394932}. Best is trial 0 with value: 0.77973.\n",
      "[I 2024-04-21 18:08:20,646] Trial 1 finished with value: 0.77973 and parameters: {'C': 1663.0547034476683}. Best is trial 0 with value: 0.77973.\n",
      "[I 2024-04-21 18:08:21,677] Trial 2 finished with value: 0.77973 and parameters: {'C': 4.283662948480398}. Best is trial 0 with value: 0.77973.\n",
      "[I 2024-04-21 18:08:22,644] Trial 3 finished with value: 0.77973 and parameters: {'C': 9.137908431133358}. Best is trial 0 with value: 0.77973.\n",
      "[I 2024-04-21 18:08:23,329] Trial 4 finished with value: 0.7797400000000001 and parameters: {'C': 0.3618307456149387}. Best is trial 4 with value: 0.7797400000000001.\n",
      "[I 2024-04-21 18:08:24,061] Trial 5 finished with value: 0.77973 and parameters: {'C': 7220.687700396874}. Best is trial 4 with value: 0.7797400000000001.\n",
      "[I 2024-04-21 18:08:24,651] Trial 6 finished with value: 0.77973 and parameters: {'C': 1.8120308687033875}. Best is trial 4 with value: 0.7797400000000001.\n",
      "[I 2024-04-21 18:08:25,299] Trial 7 finished with value: 0.77973 and parameters: {'C': 10.436451240719805}. Best is trial 4 with value: 0.7797400000000001.\n",
      "[I 2024-04-21 18:08:25,877] Trial 8 finished with value: 0.77973 and parameters: {'C': 44.275995865211385}. Best is trial 4 with value: 0.7797400000000001.\n",
      "[I 2024-04-21 18:08:26,483] Trial 9 finished with value: 0.77973 and parameters: {'C': 0.20014656658802446}. Best is trial 4 with value: 0.7797400000000001.\n",
      "[I 2024-04-21 18:08:26,484] A new study created in memory with name: no-name-d7e7b89e-97cb-400f-8351-9849e7e00891\n",
      "[I 2024-04-21 18:09:13,688] Trial 0 finished with value: 0.79464 and parameters: {'n_estimators': 100, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.79464.\n",
      "[I 2024-04-21 18:09:18,072] Trial 1 finished with value: 0.76346 and parameters: {'n_estimators': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.79464.\n",
      "[I 2024-04-21 18:09:38,167] Trial 2 finished with value: 0.79108 and parameters: {'n_estimators': 50, 'max_features': 'log2'}. Best is trial 0 with value: 0.79464.\n",
      "[I 2024-04-21 18:09:43,254] Trial 3 finished with value: 0.76607 and parameters: {'n_estimators': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.79464.\n",
      "[I 2024-04-21 18:10:07,575] Trial 4 finished with value: 0.79115 and parameters: {'n_estimators': 50, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.79464.\n",
      "[I 2024-04-21 18:10:12,367] Trial 5 finished with value: 0.76653 and parameters: {'n_estimators': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.79464.\n",
      "[I 2024-04-21 18:10:16,521] Trial 6 finished with value: 0.7642500000000001 and parameters: {'n_estimators': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.79464.\n",
      "[I 2024-04-21 18:11:48,969] Trial 7 finished with value: 0.7967599999999999 and parameters: {'n_estimators': 200, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.7967599999999999.\n",
      "[I 2024-04-21 18:12:12,245] Trial 8 finished with value: 0.79177 and parameters: {'n_estimators': 50, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.7967599999999999.\n",
      "[I 2024-04-21 18:12:31,861] Trial 9 finished with value: 0.7913600000000001 and parameters: {'n_estimators': 50, 'max_features': 'log2'}. Best is trial 7 with value: 0.7967599999999999.\n",
      "[I 2024-04-21 18:12:31,862] A new study created in memory with name: no-name-ab2f8d1d-dbc2-4d82-afb8-79c42703b013\n",
      "[I 2024-04-21 18:12:39,858] Trial 0 finished with value: 0.73392 and parameters: {'n_neighbors': 3}. Best is trial 0 with value: 0.73392.\n",
      "[I 2024-04-21 18:12:47,909] Trial 1 finished with value: 0.7313400000000001 and parameters: {'n_neighbors': 4}. Best is trial 0 with value: 0.73392.\n",
      "[I 2024-04-21 18:12:56,289] Trial 2 finished with value: 0.7558499999999999 and parameters: {'n_neighbors': 8}. Best is trial 2 with value: 0.7558499999999999.\n",
      "[I 2024-04-21 18:13:04,442] Trial 3 finished with value: 0.76448 and parameters: {'n_neighbors': 12}. Best is trial 3 with value: 0.76448.\n",
      "[I 2024-04-21 18:13:12,520] Trial 4 finished with value: 0.7566200000000001 and parameters: {'n_neighbors': 7}. Best is trial 3 with value: 0.76448.\n",
      "[I 2024-04-21 18:13:20,685] Trial 5 finished with value: 0.76997 and parameters: {'n_neighbors': 16}. Best is trial 5 with value: 0.76997.\n",
      "[I 2024-04-21 18:13:28,898] Trial 6 finished with value: 0.76448 and parameters: {'n_neighbors': 12}. Best is trial 5 with value: 0.76997.\n",
      "[I 2024-04-21 18:13:37,247] Trial 7 finished with value: 0.76997 and parameters: {'n_neighbors': 16}. Best is trial 5 with value: 0.76997.\n",
      "[I 2024-04-21 18:13:45,504] Trial 8 finished with value: 0.76997 and parameters: {'n_neighbors': 16}. Best is trial 5 with value: 0.76997.\n",
      "[I 2024-04-21 18:13:53,848] Trial 9 finished with value: 0.7729400000000001 and parameters: {'n_neighbors': 20}. Best is trial 9 with value: 0.7729400000000001.\n",
      "[I 2024-04-21 18:13:53,849] A new study created in memory with name: no-name-c6c27a82-1ce5-4f28-bc4c-093808a089d0\n",
      "[I 2024-04-21 18:13:55,724] Trial 0 finished with value: 0.7448600000000001 and parameters: {'max_depth': 4}. Best is trial 0 with value: 0.7448600000000001.\n",
      "[I 2024-04-21 18:13:57,524] Trial 1 finished with value: 0.7448600000000001 and parameters: {'max_depth': 4}. Best is trial 0 with value: 0.7448600000000001.\n",
      "[I 2024-04-21 18:14:00,570] Trial 2 finished with value: 0.76895 and parameters: {'max_depth': 8}. Best is trial 2 with value: 0.76895.\n",
      "[I 2024-04-21 18:14:05,568] Trial 3 finished with value: 0.7369600000000001 and parameters: {'max_depth': 17}. Best is trial 2 with value: 0.76895.\n",
      "[I 2024-04-21 18:14:09,184] Trial 4 finished with value: 0.76813 and parameters: {'max_depth': 10}. Best is trial 2 with value: 0.76895.\n",
      "[I 2024-04-21 18:14:14,039] Trial 5 finished with value: 0.73927 and parameters: {'max_depth': 16}. Best is trial 2 with value: 0.76895.\n",
      "[I 2024-04-21 18:14:16,491] Trial 6 finished with value: 0.76129 and parameters: {'max_depth': 6}. Best is trial 2 with value: 0.76895.\n",
      "[I 2024-04-21 18:14:19,834] Trial 7 finished with value: 0.76781 and parameters: {'max_depth': 9}. Best is trial 2 with value: 0.76895.\n",
      "[I 2024-04-21 18:14:24,123] Trial 8 finished with value: 0.75447 and parameters: {'max_depth': 13}. Best is trial 2 with value: 0.76895.\n",
      "[I 2024-04-21 18:14:25,951] Trial 9 finished with value: 0.7448600000000001 and parameters: {'max_depth': 4}. Best is trial 2 with value: 0.76895.\n",
      "[I 2024-04-21 18:14:25,952] A new study created in memory with name: no-name-9afe036b-40eb-4c37-94b1-897e38805086\n",
      "[I 2024-04-21 18:14:26,384] Trial 0 finished with value: 0.7529999999999999 and parameters: {}. Best is trial 0 with value: 0.7529999999999999.\n",
      "[I 2024-04-21 18:14:26,816] Trial 1 finished with value: 0.7529999999999999 and parameters: {}. Best is trial 0 with value: 0.7529999999999999.\n",
      "[I 2024-04-21 18:14:27,245] Trial 2 finished with value: 0.7529999999999999 and parameters: {}. Best is trial 0 with value: 0.7529999999999999.\n",
      "[I 2024-04-21 18:14:27,692] Trial 3 finished with value: 0.7529999999999999 and parameters: {}. Best is trial 0 with value: 0.7529999999999999.\n",
      "[I 2024-04-21 18:14:28,117] Trial 4 finished with value: 0.7529999999999999 and parameters: {}. Best is trial 0 with value: 0.7529999999999999.\n",
      "[I 2024-04-21 18:14:28,551] Trial 5 finished with value: 0.7529999999999999 and parameters: {}. Best is trial 0 with value: 0.7529999999999999.\n",
      "[I 2024-04-21 18:14:28,980] Trial 6 finished with value: 0.7529999999999999 and parameters: {}. Best is trial 0 with value: 0.7529999999999999.\n",
      "[I 2024-04-21 18:14:29,413] Trial 7 finished with value: 0.7529999999999999 and parameters: {}. Best is trial 0 with value: 0.7529999999999999.\n",
      "[I 2024-04-21 18:14:29,844] Trial 8 finished with value: 0.7529999999999999 and parameters: {}. Best is trial 0 with value: 0.7529999999999999.\n",
      "[I 2024-04-21 18:14:30,287] Trial 9 finished with value: 0.7529999999999999 and parameters: {}. Best is trial 0 with value: 0.7529999999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Best Score: 0.7797\n",
      "Best Parameters: {'C': 0.3618307456149387}\n",
      "Random Forest - Best Score: 0.7968\n",
      "Best Parameters: {'n_estimators': 200, 'max_features': 'sqrt'}\n",
      "k-Nearest Neighbors - Best Score: 0.7729\n",
      "Best Parameters: {'n_neighbors': 20}\n",
      "Decision Tree - Best Score: 0.7690\n",
      "Best Parameters: {'max_depth': 8}\n",
      "Naive Bayes - Best Score: 0.7530\n",
      "Best Parameters: {}\n"
     ]
    }
   ],
   "source": [
    "study_results = {}\n",
    "for name, grid in param_grids.items():\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, name, {\n",
    "        'Logistic Regression': LogisticRegression,\n",
    "        'Random Forest': RandomForestClassifier,\n",
    "        'k-Nearest Neighbors': KNeighborsClassifier,\n",
    "        'Decision Tree': DecisionTreeClassifier,\n",
    "        'Naive Bayes': GaussianNB\n",
    "    }[name], grid), n_trials=10)\n",
    "\n",
    "    study_results[name] = {\n",
    "        'Best Score': study.best_value,\n",
    "        'Best Parameters': study.best_params\n",
    "    }\n",
    "\n",
    "for classifier, result in study_results.items():\n",
    "    print(f\"{classifier} - Best Score: {result['Best Score']:.4f}\")\n",
    "    print(f\"Best Parameters: {result['Best Parameters']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec768c46a63652f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:51:52.419572699Z",
     "start_time": "2024-04-21T17:51:52.416049752Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_ensemble_classifiers(X, y, classifiers, cv_folds=5):\n",
    "    results = {}\n",
    "    for name, model in tqdm(classifiers.items()):\n",
    "        cv_scores = cross_val_score(model, X, y, cv=cv_folds, scoring='accuracy')\n",
    "        results[name] = {\n",
    "            'Mean Accuracy': np.mean(cv_scores),\n",
    "            'Standard Deviation': np.std(cv_scores),\n",
    "            'All Scores': cv_scores\n",
    "        }\n",
    "        print(f\"{name}: Mean Accuracy = {results[name]['Mean Accuracy']:.4f}, \" +\n",
    "              f\"Std Deviation = {results[name]['Standard Deviation']:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd1cd5a28d84fbf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:52:02.701398230Z",
     "start_time": "2024-04-21T17:51:52.418965069Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:05<00:05,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: Mean Accuracy = 0.8072, Std Deviation = 0.0031\n",
      "[LightGBM] [Info] Number of positive: 40000, number of negative: 40000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10161\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 40000, number of negative: 40000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10161\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 40000, number of negative: 40000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10161\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 40000, number of negative: 40000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10162\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 40000, number of negative: 40000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10160\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:09<00:00,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM: Mean Accuracy = 0.8065, Std Deviation = 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, \\\n",
    "    StackingClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "base_estimators = [\n",
    "    ('DecisionTree', DecisionTreeClassifier(max_depth=8)),\n",
    "    ('KNN', KNeighborsClassifier(n_neighbors=20)),\n",
    "    ('ExtraTrees', ExtraTreesClassifier(n_estimators=100)),\n",
    "    ('LogisticRegression', LogisticRegression(C=0.36, max_iter=5000))\n",
    "]\n",
    "\n",
    "# Voting_Soft: Mean Accuracy = 0.7947, Std Deviation = 0.0033\n",
    "# AdaBoost (with Decision Tree): Mean Accuracy = 0.7430, Std Deviation = 0.0029\n",
    "# Bagging (with Logistic Regression): Mean Accuracy = 0.7799, Std Deviation = 0.0029\n",
    "# Stacking: Mean Accuracy = 0.7937, Std Deviation = 0.0047\n",
    "\n",
    "ensemble_classifiers = {\n",
    "    # \"Voting_Soft\": VotingClassifier(estimators=base_estimators, voting='soft'),\n",
    "    # \"AdaBoost (with Decision Tree)\": AdaBoostClassifier(DecisionTreeClassifier(max_depth=8), n_estimators=50),\n",
    "    # \"Bagging (with Logistic Regression)\": BaggingClassifier(LogisticRegression(C=0.36, max_iter=5000), n_estimators=10),\n",
    "    # \"Stacking\": StackingClassifier(estimators=base_estimators,\n",
    "    #                                final_estimator=GradientBoostingClassifier(n_estimators=50, learning_rate=1)),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=300, learning_rate=0.1),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=300, learning_rate=0.1),\n",
    "\n",
    "}\n",
    "\n",
    "ensemble_classifiers_res = evaluate_ensemble_classifiers(X, y, ensemble_classifiers, cv_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3854cb8d91bfd33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:54:09.308646205Z",
     "start_time": "2024-04-21T17:53:01.456051333Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 603us/step - accuracy: 0.7199 - loss: 0.5553 - val_accuracy: 0.7793 - val_loss: 0.4589\n",
      "Epoch 2/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.7701 - loss: 0.4749 - val_accuracy: 0.7679 - val_loss: 0.4738\n",
      "Epoch 3/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.7761 - loss: 0.4662 - val_accuracy: 0.7756 - val_loss: 0.4629\n",
      "Epoch 4/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - accuracy: 0.7754 - loss: 0.4602 - val_accuracy: 0.7898 - val_loss: 0.4393\n",
      "Epoch 5/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514us/step - accuracy: 0.7835 - loss: 0.4484 - val_accuracy: 0.7763 - val_loss: 0.4513\n",
      "Epoch 6/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.7846 - loss: 0.4451 - val_accuracy: 0.7861 - val_loss: 0.4404\n",
      "Epoch 7/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7821 - loss: 0.4447 - val_accuracy: 0.7879 - val_loss: 0.4369\n",
      "Epoch 8/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.7881 - loss: 0.4394 - val_accuracy: 0.7931 - val_loss: 0.4321\n",
      "Epoch 9/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.7878 - loss: 0.4394 - val_accuracy: 0.7800 - val_loss: 0.4478\n",
      "Epoch 10/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.7866 - loss: 0.4369 - val_accuracy: 0.7936 - val_loss: 0.4290\n",
      "Epoch 11/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7918 - loss: 0.4325 - val_accuracy: 0.7915 - val_loss: 0.4282\n",
      "Epoch 12/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506us/step - accuracy: 0.7901 - loss: 0.4346 - val_accuracy: 0.7937 - val_loss: 0.4286\n",
      "Epoch 13/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.7930 - loss: 0.4310 - val_accuracy: 0.7901 - val_loss: 0.4351\n",
      "Epoch 14/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.7917 - loss: 0.4313 - val_accuracy: 0.7966 - val_loss: 0.4240\n",
      "Epoch 15/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.7899 - loss: 0.4278 - val_accuracy: 0.7968 - val_loss: 0.4230\n",
      "Epoch 16/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.7921 - loss: 0.4274 - val_accuracy: 0.7946 - val_loss: 0.4249\n",
      "Epoch 17/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.7978 - loss: 0.4225 - val_accuracy: 0.7970 - val_loss: 0.4185\n",
      "Epoch 18/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7954 - loss: 0.4228 - val_accuracy: 0.7958 - val_loss: 0.4206\n",
      "Epoch 19/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - accuracy: 0.7967 - loss: 0.4211 - val_accuracy: 0.7965 - val_loss: 0.4192\n",
      "Epoch 20/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506us/step - accuracy: 0.7924 - loss: 0.4241 - val_accuracy: 0.7962 - val_loss: 0.4175\n",
      "Epoch 21/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7956 - loss: 0.4214 - val_accuracy: 0.7959 - val_loss: 0.4190\n",
      "Epoch 22/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.7996 - loss: 0.4142 - val_accuracy: 0.7979 - val_loss: 0.4164\n",
      "Epoch 23/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7981 - loss: 0.4177 - val_accuracy: 0.7997 - val_loss: 0.4153\n",
      "Epoch 24/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505us/step - accuracy: 0.7991 - loss: 0.4171 - val_accuracy: 0.7937 - val_loss: 0.4222\n",
      "Epoch 25/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.8008 - loss: 0.4131 - val_accuracy: 0.7962 - val_loss: 0.4198\n",
      "Epoch 26/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.7967 - loss: 0.4171 - val_accuracy: 0.7987 - val_loss: 0.4156\n",
      "Epoch 27/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.8003 - loss: 0.4149 - val_accuracy: 0.8007 - val_loss: 0.4176\n",
      "Epoch 28/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506us/step - accuracy: 0.7993 - loss: 0.4135 - val_accuracy: 0.7987 - val_loss: 0.4223\n",
      "Epoch 29/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.7984 - loss: 0.4155 - val_accuracy: 0.8007 - val_loss: 0.4160\n",
      "Epoch 30/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512us/step - accuracy: 0.8021 - loss: 0.4090 - val_accuracy: 0.7973 - val_loss: 0.4187\n",
      "Epoch 31/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.8010 - loss: 0.4119 - val_accuracy: 0.8008 - val_loss: 0.4158\n",
      "Epoch 32/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507us/step - accuracy: 0.8014 - loss: 0.4093 - val_accuracy: 0.7922 - val_loss: 0.4307\n",
      "Epoch 33/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515us/step - accuracy: 0.8020 - loss: 0.4104 - val_accuracy: 0.7951 - val_loss: 0.4227\n",
      "Epoch 34/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.8031 - loss: 0.4082 - val_accuracy: 0.8010 - val_loss: 0.4182\n",
      "Epoch 35/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.8024 - loss: 0.4088 - val_accuracy: 0.7998 - val_loss: 0.4123\n",
      "Epoch 36/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.8017 - loss: 0.4108 - val_accuracy: 0.8002 - val_loss: 0.4163\n",
      "Epoch 37/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.8028 - loss: 0.4078 - val_accuracy: 0.8007 - val_loss: 0.4138\n",
      "Epoch 38/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.8064 - loss: 0.4045 - val_accuracy: 0.7970 - val_loss: 0.4189\n",
      "Epoch 39/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.8068 - loss: 0.4022 - val_accuracy: 0.8011 - val_loss: 0.4156\n",
      "Epoch 40/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.8056 - loss: 0.4055 - val_accuracy: 0.7982 - val_loss: 0.4228\n",
      "Epoch 41/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 637us/step - accuracy: 0.8059 - loss: 0.4039 - val_accuracy: 0.7972 - val_loss: 0.4236\n",
      "Epoch 42/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.8050 - loss: 0.4038 - val_accuracy: 0.8025 - val_loss: 0.4168\n",
      "Epoch 43/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.8077 - loss: 0.4029 - val_accuracy: 0.7981 - val_loss: 0.4236\n",
      "Epoch 44/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.8084 - loss: 0.4000 - val_accuracy: 0.7994 - val_loss: 0.4190\n",
      "Epoch 45/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.8085 - loss: 0.4011 - val_accuracy: 0.8023 - val_loss: 0.4156\n",
      "Epoch 46/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.8060 - loss: 0.4003 - val_accuracy: 0.8016 - val_loss: 0.4146\n",
      "Epoch 47/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step - accuracy: 0.8065 - loss: 0.4015 - val_accuracy: 0.7972 - val_loss: 0.4236\n",
      "Epoch 48/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - accuracy: 0.8092 - loss: 0.3973 - val_accuracy: 0.7980 - val_loss: 0.4275\n",
      "Epoch 49/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.8085 - loss: 0.3970 - val_accuracy: 0.8005 - val_loss: 0.4188\n",
      "Epoch 50/50\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517us/step - accuracy: 0.8094 - loss: 0.3980 - val_accuracy: 0.8006 - val_loss: 0.4160\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-4 * 10**( -(epoch // 10))\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f14b4c95e98595e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T17:54:31.235125091Z",
     "start_time": "2024-04-21T17:54:31.106408585Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('./models/nn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb5bc84bcb0822",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
